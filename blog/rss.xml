<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>The Cadenza Project Blog</title>
        <link>https://cadenzaproject.github.io/blog</link>
        <description>The Cadenza Project Blog</description>
        <lastBuildDate>Thu, 01 May 2025 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Cadenza Lyric Intelligibility Prediction Challenge (CLIP)]]></title>
            <link>https://cadenzaproject.github.io/blog/Preannouncing CLIP</link>
            <guid>https://cadenzaproject.github.io/blog/Preannouncing CLIP</guid>
            <pubDate>Thu, 01 May 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[Dear colleague,]]></description>
            <content:encoded><![CDATA[<p>Dear colleague,
It gives us great pleasure to pre-announce the next Cadenza Challenge for music processing and hearing difference.
This autumn we will be running the Cadenza Lyric Intelligibility Prediction Challenge (CLIP).
We're hoping this will be accepted as an ICASSP 2026 Grand Challenge.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="the-challenge">The Challenge<a href="https://cadenzaproject.github.io/blog/Preannouncing%20CLIP#the-challenge" class="hash-link" aria-label="Direct link to The Challenge" title="Direct link to The Challenge">​</a></h2>
<p>To develop better music processing through machine learning, we need reliable way to automatically evaluate the audio.
For music with lyrics, then we need a metric to evaluate the intelligibility of the sung words.
The metric would come from a predictive model that takes as input audio and estimates the lyric intelligibility score that someone would achieve in a listening test.</p>
<p>With the development of large language models and foundation models for speech and music, there is great potential to significantly improve the current state-of-the-art.
The music will be genres like pop and rock. Some of this will be as-is, other will be passed through a hearing loss simulator to mimic listeners with hearing loss but not wearing hearing aids.</p>
<!-- -->
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="what-will-be-provided">What will be provided<a href="https://cadenzaproject.github.io/blog/Preannouncing%20CLIP#what-will-be-provided" class="hash-link" aria-label="Direct link to What will be provided" title="Direct link to What will be provided">​</a></h3>
<ul>
<li>Training, evaluation and test tests of music.</li>
<li>Ground truth lyric intelligibility from listening tests.</li>
<li>Software tools including a baseline system based on xxx.</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="important-dates">Important Dates<a href="https://cadenzaproject.github.io/blog/Preannouncing%20CLIP#important-dates" class="hash-link" aria-label="Direct link to Important Dates" title="Direct link to Important Dates">​</a></h3>
<p>All dates are to be intended anywhere on earth time (AoE) and are provisional.</p>
<ul>
<li>1st September 2025: Launch of challenge, release of data.</li>
<li>1st November 2025: Release of evaluation data and opening of submission window.</li>
<li>1st December 2025: Submission deadline. All entrants must have submitted their predictions plus a draft of their technical report.</li>
<li>If this is accepted as an ICASSP Grand Challenge<!-- -->
<ul>
<li>7th December 2025. Invited papers for ICASSP session</li>
<li>2-8 May 2026. Session at ICASSP 2026</li>
</ul>
</li>
</ul>
<p>We will know whether this is an ICASSP grand challenge in July 2025.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="stay-informed">Stay informed<a href="https://cadenzaproject.github.io/blog/Preannouncing%20CLIP#stay-informed" class="hash-link" aria-label="Direct link to Stay informed" title="Direct link to Stay informed">​</a></h3>
<p>To stay informed please sign up to our <a href="https://groups.google.com/g/cadenza-challenge/" target="_blank" rel="noopener noreferrer">Google Group</a></p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="organisers">Organisers<a href="https://cadenzaproject.github.io/blog/Preannouncing%20CLIP#organisers" class="hash-link" aria-label="Direct link to Organisers" title="Direct link to Organisers">​</a></h3>
<ul>
<li>Michael A. Akeroyd, University of Nottingham</li>
<li>Scott Bannister, University of Leeds</li>
<li>Jon P Barker, University of Sheffield</li>
<li>Trevor J. Cox, University of Salford</li>
<li>Bruno Fazenda, University of Salford</li>
<li>Jennifer Firth, University of Nottingham</li>
<li>Simone Graetzer, University of Salford</li>
<li>Alinka Greasley, University of Leeds</li>
<li>Gerardo Roa-Dabike, University of Sheffield</li>
<li>Rebecca R. Vos, University of Salford</li>
<li>William M. Whitmer, University of Nottingham</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="funded-by">Funded by<a href="https://cadenzaproject.github.io/blog/Preannouncing%20CLIP#funded-by" class="hash-link" aria-label="Direct link to Funded by" title="Direct link to Funded by">​</a></h3>
<p>Engineering and Physical Sciences Research Council (EPSRC), UK</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="partners">Partners<a href="https://cadenzaproject.github.io/blog/Preannouncing%20CLIP#partners" class="hash-link" aria-label="Direct link to Partners" title="Direct link to Partners">​</a></h3>
<p>RNID, Google, Logitech, Sonova, BBC R&amp;D, Oldenburg University.</p>]]></content:encoded>
            <category>cadenza</category>
            <category>launch</category>
            <category>CLIP</category>
        </item>
        <item>
            <title><![CDATA[Listener panel study update]]></title>
            <link>https://cadenzaproject.github.io/blog/Listener panel study update</link>
            <guid>https://cadenzaproject.github.io/blog/Listener panel study update</guid>
            <pubDate>Thu, 05 Oct 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[We have two major updates from the Cadenza project.]]></description>
            <content:encoded><![CDATA[<p>We have two major updates from the Cadenza project.</p>
<p>First, we completed the sensory panel study in which our participants with hearing loss developed audio quality scales for use in our listening experiments.
We presented our study findings at the International Conference of Music Perception and Cognition (ICMPC) in Tokyo, Japan in August and at the Basic Auditory Science (BAS) conference in London in September.</p>
<!-- -->
<div style="text-align:center"><figure id="fig1"><img width="400" src="https://cadenzaproject.github.io/img/blog_2023-10-05/apsco.png"></figure></div>
<p>Second, the entrants in the <a href="https://cadenzachallenge.org/docs/cadenza1/cc1_intro" target="_blank" rel="noopener noreferrer">First Cadenza Challenge</a> have now submitted systems they devised to improve the audio quality of various music samples.
These samples have been tailored for the hearing profiles of our listener panel participants and are currently being prepared for our online software.</p>
<p><strong>We will be releasing the main online listening experiment over the coming days!</strong></p>
<p>On 20th September, we ran a webinar for our listener panel. In the first part, we gave a short talk summarising the aims and results of the sensory panel study.
You can watch the recording of this event in the next video.</p>
<div style="text-align:center"><iframe width="750" height="500" src="https://www.youtube.com/embed/-DW3S5yjU90?si=UMc1FjMIGovgBXsO" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"></iframe></div>
<p><strong>Our thanks to the challenge entrants for their submissions!</strong></p>]]></content:encoded>
            <category>sensory panel</category>
        </item>
        <item>
            <title><![CDATA[Sensory evaluation study update]]></title>
            <link>https://cadenzaproject.github.io/blog/Sensory evaluation study update</link>
            <guid>https://cadenzaproject.github.io/blog/Sensory evaluation study update</guid>
            <pubDate>Tue, 02 May 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[We are now reaching the end of our sensory evaluation study, where a panel of twelve listeners who use hearing aids]]></description>
            <content:encoded><![CDATA[<p>We are now reaching the end of our sensory evaluation study, where a panel of twelve listeners who use hearing aids
have worked across online music listening tasks and three focus groups, to reach a consensus on the important
perceptual attributes of music audio quality.</p>
<!-- -->
<p>Starting from 373 unique terms used by participants to describe music audio quality, a discussion process
was completed as outlined in the image below:</p>
<figure id="fig1"><img width="1000" src="https://cadenzaproject.github.io/img/Sensory_Eval_Flowchart.jpg"><figcaption>Figure 1, Objectives of each Focus Group session.</figcaption></figure>
<p>At this stage in the work, we wanted to share the current state of these perceptual attributes and short definitions:</p>
<table><thead><tr><th>Attribute</th><th>Short Definition</th></tr></thead><tbody><tr><td>Overall Audio Quality</td><td>Perceived audio quality results from judgments of the sound of the music, in relation to a person’s expectations of how the music should ideally sound to them.</td></tr><tr><td>Clarity</td><td>Clarity refers to how well you can hear and distinguish between the different instruments and elements within the music.</td></tr><tr><td>Harshness</td><td>Harshness refers to an uncomfortable overemphasis of certain parts of the sound. It is most often heard in the treble resulting in a piercing, screechy or sharp sounds.</td></tr><tr><td>Distortion</td><td>Distortion can be caused by artefacts that shouldn’t be present e.g., noise, hiss, pops or crackles. It can also be caused by the pitches sounding wrong. Music with No distortion sounds like an authentic version of what was performed.</td></tr><tr><td>Spaciousness</td><td>Spaciousness refers to how much you feel the music is ‘coloured’ by the performance space, and how much you can hear the reverberations and sense of space.</td></tr><tr><td>Treble Strength</td><td>Treble strength refers to the perceived strength or prominence of sound qualities that are characterised by higher frequencies in the treble range, or similarly, sounds, instruments or voices with higher pitches.</td></tr><tr><td>Middle Strength</td><td>Middle strength refers to the perceived strength or prominence of sound qualities that are characterised by middle frequencies found between bass and treble ranges, or similarly, sounds, instruments, or voices that pitches perceived as being between lower and higher pitches.</td></tr><tr><td>Bass Strength</td><td>Bass strength refers to the perceived strength or prominence of sound qualities that are characterised by lower frequencies in the bass range, or similarly, sounds, instruments or voices with lower pitches.</td></tr><tr><td>Frequency Balance</td><td>Frequency balance refers to the perceived balance between treble (or higher pitch) and bass (or lower pitch) sounds.</td></tr></tbody></table>
<p>Our next steps in the perceptual research will involve further data collection and testing of these attributes,
to understand which are the strongest predictors of overall audio quality. This is an important process as enhanced
music signals submitted by challenge entrants will be scored on these attributes by a listening panel,
and so the necessity of these attributes requires some initial testing.</p>
<p>As always, we would like to express our sincere gratitude and thanks to our sensory panel group for their
incredible commitment, motivation, and contribution to this research!</p>]]></content:encoded>
            <category>sensory panel</category>
        </item>
        <item>
            <title><![CDATA[Sensory evaluation study]]></title>
            <link>https://cadenzaproject.github.io/blog/Sensory evaluation study</link>
            <guid>https://cadenzaproject.github.io/blog/Sensory evaluation study</guid>
            <pubDate>Mon, 30 Jan 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[Here at Cadenza our sensory evaluation work to define audio quality for hearing impaired listeners is underway. We want to understand better how hearing-impaired listeners perceive audio quality in music and develop quality metrics that will subsequently be used by our listener panel to rate the systems submitted by challenge entrants. Through careful listening tasks and group discussion, the sensory panel will arrive at a consensus about important sound quality attributes and how these should be measured. You can find out more about this process on the Sensory Evaluation page.]]></description>
            <content:encoded><![CDATA[<p>Here at Cadenza our sensory evaluation work to define audio quality for hearing impaired listeners is underway. We want to understand better how hearing-impaired listeners perceive audio quality in music and develop quality metrics that will subsequently be used by our listener panel to rate the systems submitted by challenge entrants. Through careful listening tasks and group discussion, the sensory panel will arrive at a consensus about important sound quality attributes and how these should be measured. You can find out more about this process on the <a href="https://cadenzaproject.github.io/docs/learning_resources/Perceptual_testing/edu_PT_sensory_Evaluation">Sensory Evaluation page</a>.</p>
<!-- -->
<p>The first task was an individual elicitation task in which we asked twelve listeners with hearing impairment to provide single-word perceptual terms to describe various music excerpts provided to them. This resulted in hundreds of unique attributes used to describe sound quality, of which 89 were used more than four times (see  <a href="https://cadenzaproject.github.io/blog/Sensory%20evaluation%20study#fig1">Fig. 1</a>) and 87 were used two or three times (see <a href="https://cadenzaproject.github.io/blog/Sensory%20evaluation%20study#fig2">Fig. 2</a>). This provided the starting point for the first Focus group which sought to identify the most important attributes and to identify ways of grouping the attributes into perceptual dimensions that could be captured in the quality metric.</p>
<p>The outcome of Focus group one was a spatial mapping of the ways in which the panel grouped attributes together which was used as a starting point for Focus group two (see <a href="https://cadenzaproject.github.io/blog/Sensory%20evaluation%20study#fig3">Fig. 3</a>). The panel then discussed further the meaning and grouping of different terms to reach consensus about important dimensions. In February, we will carry out a third Focus group to arrive at final dimensions, how these can be defined, and how they can be rated or scored in the challenges.</p>
<p>We would like to thank our Sensory panel group for their ongoing motivation and commitment with this challenging task!</p>
<figure id="fig1"><img width="500" src="https://cadenzaproject.github.io/img/sensory_blog_1.png"><figcaption>Figure 1, 89 terms that were used four or more times to describe the musical excerpts.</figcaption></figure>
<figure id="fig2"><img width="500" src="https://cadenzaproject.github.io/img/sensory_blog_2.png"><figcaption>Figure 2, 87 terms that were used twice or three times to describe the musical excerpts.</figcaption></figure>
<figure id="fig3"><img width="500" src="https://cadenzaproject.github.io/img/sensory_blog_3.jpg"><figcaption>Figure 3, starting point for focus group two, discussing the further meaning and grouping of different terms.</figcaption></figure>]]></content:encoded>
            <category>sensory panel</category>
        </item>
        <item>
            <title><![CDATA[Welcome]]></title>
            <link>https://cadenzaproject.github.io/blog/welcome</link>
            <guid>https://cadenzaproject.github.io/blog/welcome</guid>
            <pubDate>Tue, 03 Jan 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[Welcome to the new Cadenza webpage. We will be using this page to post the latest news about our forthcoming machine learning challenges and workshops, as well as posts discussing the tools and techniques that we are using in our baseline systems.]]></description>
            <content:encoded><![CDATA[<p>Welcome to the new Cadenza webpage. We will be using this page to post the latest news about our forthcoming machine learning challenges and workshops, as well as posts discussing the tools and techniques that we are using in our baseline systems.</p>
]]></content:encoded>
            <author>clarity-group@sheffield.ac.uk (Jon Barker)</author>
            <category>cadenza</category>
            <category>hello</category>
        </item>
    </channel>
</rss>
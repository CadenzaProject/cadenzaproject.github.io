/*! For license information please see b2acd33a.1a7856ee.js.LICENSE.txt */
(self.webpackChunkcadenza=self.webpackChunkcadenza||[]).push([[672,4404],{32176:(e,n,i)=>{"use strict";i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>u,frontMatter:()=>o,metadata:()=>l,toc:()=>d});var t=i(74848),r=i(28453),a=i(85176);i(28770);const o={id:"cc1_intro",title:"The 1st Cadenza Challenge",sidebar_label:"Cadenza 1 Introduction",sidebar_position:1},s="Overview",l={id:"cadenza1/cc1_intro",title:"The 1st Cadenza Challenge",description:"* Registration are closed!!",source:"@site/docs/cadenza1/cc1_intro.md",sourceDirName:"cadenza1",slug:"/cadenza1/cc1_intro",permalink:"/docs/cadenza1/cc1_intro",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{id:"cc1_intro",title:"The 1st Cadenza Challenge",sidebar_label:"Cadenza 1 Introduction",sidebar_position:1},sidebar:"tutorialSidebar_cad1",next:{title:"Summary Task 1",permalink:"/docs/cadenza1/cc1_summary_task1"}},c={},d=[{value:"Task 1: Headphones",id:"task-1-headphones",level:2},{value:"Task 2: Car",id:"task-2-car",level:2}];function h(e){const n={a:"a",admonition:"admonition",em:"em",h1:"h1",h2:"h2",header:"header",hr:"hr",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.admonition,{type:"info",children:(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Registration are closed!!"}),"\n"]})}),"\n",(0,t.jsxs)(n.p,{children:["The Cadenza Challenges are about improving the ",(0,t.jsx)(n.strong,{children:"perceived audio quality of recorded music for people with a hearing loss"}),"."]}),"\n",(0,t.jsx)(n.admonition,{title:"Audio Quality",type:"note",children:(0,t.jsxs)(n.p,{children:["What do we mean by audio quality? Imagine listening to the same music track in two different ways.\nFirst listening via a low quality mp3 played on a cheap cell phone, and then via a high quality wav heard over\nstudio-grade loudspeaker monitors. The underlying music is the same in both cases, but the ",(0,t.jsx)(n.em,{children:"audio quality"})," is very\ndifferent - this is what we are interested in."]})}),"\n",(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"overview",children:"Overview"})}),"\n",(0,t.jsx)(n.p,{children:"The tasks are based on two common listening scenarios:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Task 1: headphones."}),"\n",(0,t.jsx)(n.li,{children:"Task 2: in the car."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"You can enter one or both tasks."}),"\n",(0,t.jsx)(n.h2,{id:"task-1-headphones",children:"Task 1: Headphones"}),"\n",(0,t.jsx)("iframe",{width:"100%",height:"560",src:"https://www.youtube.com/embed/suGTTolF1e4",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",allowfullscreen:!0}),"\n",(0,t.jsx)(n.p,{children:"Someone with a hearing loss is listening via headphones, not using their hearing aids. As Figure 1 shows, the machine learning challenge here is to first demix stereo tracks into a VDBO (vocal, drums, bass and other) representation. This then allows a personalised remixing for the listener that has better audio quality. For example, for some music you might amplify the vocals to improve the audibility of the lyrics."}),"\n",(0,t.jsxs)(n.p,{children:["To evaluate the quality of the demixing, the objective measure ",(0,t.jsx)(n.a,{href:"../learning_resources/Hearing_aid_processing/edu_HAP_HA_processed_speech#haaqi-hearing-aid-audio-quality-index",children:"HAAQI (Hearing aid audio quality index)"})," is used. The evaluation of the remixed version will be via our listening panel."]}),"\n",(0,t.jsxs)(n.p,{children:["The block that can be changed by you is labelled ",(0,t.jsx)(n.em,{children:"Enhancement"})," in Figure 1."]}),"\n",(0,t.jsx)(n.p,{children:"While the main focus is on demixing/remixing, we'll accept entries using alternative signal processing approaches that can improve music for people with a hearing loss. Your entry would replace the whole box labelled enhancement."}),"\n",(0,t.jsxs)("figure",{id:"fig1",children:[(0,t.jsx)("img",{width:"800",src:(0,a.Ay)("/img/headphone_simple_v3.png")}),(0,t.jsx)("figcaption",{children:"Figure 1, The baseline for the headphone listening scenario (Task 1). For simplicity, not all signal paths are shown."})]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"task-2-car",children:"Task 2: Car"}),"\n",(0,t.jsx)("iframe",{width:"100%",height:"560",src:"https://www.youtube.com/embed/lgMNux9A3q4",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",allowfullscreen:!0}),"\n",(0,t.jsxs)(n.p,{children:["The listener is wearing their hearing aids, sitting in a car and listening to recorded music played over the car stereo (see Figure 2). Your task is to process the music played from the stereo to improve the audio quality allowing for the presence of the car noise. You have access to the car speed, which gives an estimation of the power spectrum of the noise but not the noise signal itself, so this is not a noise cancellation task. The block that can be changed is labelled ",(0,t.jsx)(n.em,{children:"Enhancement."})]}),"\n",(0,t.jsxs)("figure",{id:"fig2",children:[(0,t.jsx)("img",{width:"250",src:(0,a.Ay)("/img/Car_scenario.png")}),(0,t.jsx)("figcaption",{children:"Figure 2, The arrangement of the listener and speakers for the car listening scenario (Task 2)."})]}),"\n",(0,t.jsxs)("figure",{id:"fig3",children:[(0,t.jsx)("img",{width:"800",src:(0,a.Ay)("/img/car_simple_v2.png")}),(0,t.jsx)("figcaption",{children:"Figure 3, The baseline for the car listening scenario (Task 2). For simplicity, not all signal paths are shown."})]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h1,{id:"watch-the-ukan-webinar-machine-learning-challenges-to-improve-hearing-devices-clarity--cadenza-projects",children:"Watch the UKAN+ Webinar: Machine Learning Challenges to Improve Hearing Devices: Clarity & Cadenza Projects"}),"\n",(0,t.jsxs)(n.p,{children:["For more details on the ",(0,t.jsx)(n.a,{href:"https://claritychallenge.org/",children:"Clarity"})," and Cadenza projects, please see this recording of the webinar given by Trevor Cox, Alinka Greasley, and Rebecca Vos on the topic:"]}),"\n",(0,t.jsx)("iframe",{width:"100%",height:"560",src:"https://www.youtube.com/embed/7dUZ-lDsQMM",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",allowfullscreen:!0})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(h,{...e})}):h(e)}},28770:(e,n,i)=>{"use strict";i.d(n,{CU:()=>o});var t=i(96540),r="https://platform.twitter.com/widgets.js",a="createTimeline",o=function(e){var n=t.useRef(null),o=t.useState(!0),s=o[0],l=o[1];return t.useEffect((function(){var t=!0;return i(62491)(r,"twitter-embed",(function(){if(window.twttr){if(t){if(!window.twttr.widgets[a])return void console.error("Method "+a+" is not present anymore in twttr.widget api");var i=function(){var i,t,r=Object.assign({},e.options);return null!=e&&e.autoHeight&&(r.height=null===(i=n.current)||void 0===i||null===(t=i.parentNode)||void 0===t?void 0:t.offsetHeight),r=Object.assign({},r,{theme:null==e?void 0:e.theme,linkColor:null==e?void 0:e.linkColor,borderColor:null==e?void 0:e.borderColor,lang:null==e?void 0:e.lang,tweetLimit:null==e?void 0:e.tweetLimit,ariaPolite:null==e?void 0:e.ariaPolite})}();i=function(n){return n.chrome="",e.noHeader&&(n.chrome=n.chrome+" noheader"),e.noFooter&&(n.chrome=n.chrome+" nofooter"),e.noBorders&&(n.chrome=n.chrome+" noborders"),e.noScrollbar&&(n.chrome=n.chrome+" noscrollbar"),e.transparent&&(n.chrome=n.chrome+" transparent"),n}(i),window.twttr.widgets[a]({sourceType:e.sourceType,screenName:e.screenName,userId:e.userId,ownerScreenName:e.ownerScreenName,slug:e.slug,id:e.id||e.widgetId,url:e.url},null==n?void 0:n.current,i).then((function(n){l(!1),e.onLoad&&e.onLoad(n)}))}}else console.error("Failure to load window.twttr, aborting load")})),function(){t=!1}}),[]),t.createElement(t.Fragment,null,s&&t.createElement(t.Fragment,null,e.placeholder),t.createElement("div",{ref:n}))}},62491:(e,n,i)=>{var t,r,a;a=function(){var e,n,i=document,t=i.getElementsByTagName("head")[0],r=!1,a="push",o="readyState",s="onreadystatechange",l={},c={},d={},h={};function u(e,n){for(var i=0,t=e.length;i<t;++i)if(!n(e[i]))return r;return 1}function p(e,n){u(e,(function(e){return n(e),1}))}function m(n,i,t){n=n[a]?n:[n];var r=i&&i.call,o=r?i:t,s=r?n.join(""):i,f=n.length;function w(e){return e.call?e():l[e]}function v(){if(! --f)for(var e in l[s]=1,o&&o(),d)u(e.split("|"),w)&&!p(d[e],w)&&(d[e]=[])}return setTimeout((function(){p(n,(function n(i,t){return null===i?v():(t||/^https?:\/\//.test(i)||!e||(i=-1===i.indexOf(".js")?e+i+".js":e+i),h[i]?(s&&(c[s]=1),2==h[i]?v():setTimeout((function(){n(i,!0)}),0)):(h[i]=1,s&&(c[s]=1),void g(i,v)))}))}),0),m}function g(e,r){var a,l=i.createElement("script");l.onload=l.onerror=l[s]=function(){l[o]&&!/^c|loade/.test(l[o])||a||(l.onload=l[s]=null,a=1,h[e]=2,r())},l.async=1,l.src=n?e+(-1===e.indexOf("?")?"?":"&")+n:e,t.insertBefore(l,t.lastChild)}return m.get=g,m.order=function(e,n,i){!function t(r){r=e.shift(),e.length?m(r,t):m(r,n,i)}()},m.path=function(n){e=n},m.urlArgs=function(e){n=e},m.ready=function(e,n,i){e=e[a]?e:[e];var t,r=[];return!p(e,(function(e){l[e]||r[a](e)}))&&u(e,(function(e){return l[e]}))?n():(t=e.join("|"),d[t]=d[t]||[],d[t][a](n),i&&i(r)),m},m.done=function(e){m([null],e)},m},e.exports?e.exports=a():void 0===(r="function"==typeof(t=a)?t.call(n,i,n,e):t)||(e.exports=r)},28453:(e,n,i)=>{"use strict";i.d(n,{R:()=>o,x:()=>s});var t=i(96540);const r={},a=t.createContext(r);function o(e){const n=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);
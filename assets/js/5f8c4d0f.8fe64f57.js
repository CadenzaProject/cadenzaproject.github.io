"use strict";(self.webpackChunkcadenza=self.webpackChunkcadenza||[]).push([[1536],{91341:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>d,contentTitle:()=>r,default:()=>o,frontMatter:()=>t,metadata:()=>l,toc:()=>c});var i=s(85893),a=s(11151);s(44996),s(29512);const t={id:"data_overview",title:"ICASSP 2024 Data",sidebar_label:"Data specification",sidebar_position:4.2},r=void 0,l={id:"icassp_2024/data/data_overview",title:"ICASSP 2024 Data",description:"To obtain the data and baseline code, please see the download page.",source:"@site/docs/icassp_2024/data/icassp2024_data_overview.md",sourceDirName:"icassp_2024/data",slug:"/icassp_2024/data/data_overview",permalink:"/docs/icassp_2024/data/data_overview",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:4.2,frontMatter:{id:"data_overview",title:"ICASSP 2024 Data",sidebar_label:"Data specification",sidebar_position:4.2},sidebar:"tutorialSidebar_icassp2024",previous:{title:"The Challenge Data",permalink:"/docs/category/the-challenge-data-1"},next:{title:"Listener Metadata",permalink:"/docs/icassp_2024/data/data_listener"}},d={},c=[{value:"A. Training, validation and evaluation data",id:"a-training-validation-and-evaluation-data",level:2},{value:"A.1 Training data",id:"a1-training-data",level:3},{value:"A.2 Validation data",id:"a2-validation-data",level:3},{value:"A.3 Evaluation (test) set",id:"a3-evaluation-test-set",level:3},{value:"B. Training augmentation data",id:"b-training-augmentation-data",level:2},{value:"B.1 New Scenes",id:"b1-new-scenes",level:3},{value:"B.2 Augmenting tracks",id:"b2-augmenting-tracks",level:3},{value:"C. Metadata Information",id:"c-metadata-information",level:2},{value:"C.1 Listener characteristics",id:"c1-listener-characteristics",level:3},{value:"C.2 Gains",id:"c2-gains",level:3},{value:"C.3 Head and loudspeaker positions",id:"c3-head-and-loudspeaker-positions",level:3},{value:"C.4 Scenes",id:"c4-scenes",level:3},{value:"C.5 Scene-listeners",id:"c5-scene-listeners",level:3},{value:"C.6 MUSDB18-HQ",id:"c6-musdb18-hq",level:3},{value:"C.7 Signals at hearing aid microphones",id:"c7-signals-at-hearing-aid-microphones",level:3},{value:"References",id:"references",level:2}];function h(e){const n={a:"a",admonition:"admonition",annotation:"annotation",br:"br",code:"code",em:"em",h2:"h2",h3:"h3",li:"li",math:"math",mi:"mi",mo:"mo",mrow:"mrow",ol:"ol",p:"p",pre:"pre",semantics:"semantics",span:"span",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.a)(),...e.components},{Details:s}=n;return s||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(n.p,{children:["To obtain the data and baseline code, please see the ",(0,i.jsx)(n.a,{href:"../take_part/download",children:"download page"}),"."]}),"\n",(0,i.jsx)(n.h2,{id:"a-training-validation-and-evaluation-data",children:"A. Training, validation and evaluation data"}),"\n",(0,i.jsxs)(n.p,{children:["The music dataset is based on MUSDB18-HQ [",(0,i.jsx)(n.a,{href:"#refs",children:"1"}),"] and a subset of the OlHeaD-HRTF [",(0,i.jsx)(n.a,{href:"#refs",children:"2"}),"]."]}),"\n",(0,i.jsx)(n.h3,{id:"a1-training-data",children:"A.1 Training data"}),"\n",(0,i.jsx)(n.p,{children:"The training data needs to be generated by the entrants (to reduce download size). We provide:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["A mirror of the MUSDB18-HQ training split. (22 GB)","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"100 songs."}),"\n",(0,i.jsx)(n.li,{children:"44,100 Hz sample rate."}),"\n",(0,i.jsx)(n.li,{children:"16-bit."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["A set of 96 HRTFs. (300 KB)","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"16 subjects heads"}),"\n",(0,i.jsxs)(n.li,{children:["6 different loudspeaker angle positions (",(0,i.jsxs)(n.span,{className:"katex",children:[(0,i.jsx)(n.span,{className:"katex-mathml",children:(0,i.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(n.semantics,{children:[(0,i.jsx)(n.mrow,{children:(0,i.jsx)(n.mo,{children:"\xb1"})}),(0,i.jsx)(n.annotation,{encoding:"application/x-tex",children:"\\pm"})]})})}),(0,i.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"0.6667em",verticalAlign:"-0.0833em"}}),(0,i.jsx)(n.span,{className:"mord",children:"\xb1"})]})})]})," 22.5",(0,i.jsxs)(n.span,{className:"katex",children:[(0,i.jsx)(n.span,{className:"katex-mathml",children:(0,i.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(n.semantics,{children:[(0,i.jsx)(n.mrow,{children:(0,i.jsx)(n.mi,{mathvariant:"normal",children:"\xb0"})}),(0,i.jsx)(n.annotation,{encoding:"application/x-tex",children:"\\degree"})]})})}),(0,i.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"0.6944em"}}),(0,i.jsx)(n.span,{className:"mord",children:"\xb0"})]})})]}),", ",(0,i.jsxs)(n.span,{className:"katex",children:[(0,i.jsx)(n.span,{className:"katex-mathml",children:(0,i.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(n.semantics,{children:[(0,i.jsx)(n.mrow,{children:(0,i.jsx)(n.mo,{children:"\xb1"})}),(0,i.jsx)(n.annotation,{encoding:"application/x-tex",children:"\\pm"})]})})}),(0,i.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"0.6667em",verticalAlign:"-0.0833em"}}),(0,i.jsx)(n.span,{className:"mord",children:"\xb1"})]})})]})," 30.0",(0,i.jsxs)(n.span,{className:"katex",children:[(0,i.jsx)(n.span,{className:"katex-mathml",children:(0,i.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(n.semantics,{children:[(0,i.jsx)(n.mrow,{children:(0,i.jsx)(n.mi,{mathvariant:"normal",children:"\xb0"})}),(0,i.jsx)(n.annotation,{encoding:"application/x-tex",children:"\\degree"})]})})}),(0,i.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"0.6944em"}}),(0,i.jsx)(n.span,{className:"mord",children:"\xb0"})]})})]}),", and ",(0,i.jsxs)(n.span,{className:"katex",children:[(0,i.jsx)(n.span,{className:"katex-mathml",children:(0,i.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(n.semantics,{children:[(0,i.jsx)(n.mrow,{children:(0,i.jsx)(n.mo,{children:"\xb1"})}),(0,i.jsx)(n.annotation,{encoding:"application/x-tex",children:"\\pm"})]})})}),(0,i.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"0.6667em",verticalAlign:"-0.0833em"}}),(0,i.jsx)(n.span,{className:"mord",children:"\xb1"})]})})]})," 37.5",(0,i.jsxs)(n.span,{className:"katex",children:[(0,i.jsx)(n.span,{className:"katex-mathml",children:(0,i.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(n.semantics,{children:[(0,i.jsx)(n.mrow,{children:(0,i.jsx)(n.mi,{mathvariant:"normal",children:"\xb0"})}),(0,i.jsx)(n.annotation,{encoding:"application/x-tex",children:"\\degree"})]})})}),(0,i.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"0.6944em"}}),(0,i.jsx)(n.span,{className:"mord",children:"\xb0"})]})})]}),")"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["400 scenes descriptions:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"The MUSDB18-HQ track for each scene."}),"\n",(0,i.jsx)(n.li,{children:"4 different left/right loudspeaker angle position"}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.li,{children:"A script (part of the software) to generate the training set."}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"To generate the training set please do:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Download and install PyClarity as described in ",(0,i.jsx)(n.a,{href:"../take_part/download#a-software",children:"Download data and software"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["Download and extract the ",(0,i.jsx)(n.strong,{children:"core"})," and ",(0,i.jsx)(n.strong,{children:"train"})," data packages as described in ",(0,i.jsx)(n.a,{href:"../take_part/download#b-data",children:"Download data and software"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["Go to ",(0,i.jsx)(n.code,{children:"recipes/cad_icassp_2024/generate_dataset"})," directory"]}),"\n",(0,i.jsxs)(n.li,{children:["Run ",(0,i.jsx)(n.code,{children:"generate_at_mic_musdb18.py"})," setting the ",(0,i.jsx)(n.code,{children:"path.root"})," parameter to the directory where you saved the ",(0,i.jsx)(n.strong,{children:"core"})," data."]}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"python3 generate_at_mic_musdb18.py \\\n  path.root=/Volumes/cadenza_data/icassp_2024/\n"})}),"\n",(0,i.jsx)(n.p,{children:"The script will iterate through the scenes, generating the at the microphone (at-mic) music samples.\nThis process will create:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["The directory ",(0,i.jsx)(n.code,{children:".../icassp_2024/audio/at_mic_music"}),", where the at-the-microphone signals will be saved (88 GB). This location can be changed by setting the ",(0,i.jsx)(n.code,{children:"path.output_music_dir"})," parameter."]}),"\n",(0,i.jsxs)(n.li,{children:["The file ",(0,i.jsx)(n.code,{children:".../icassp_2024/metadata/at_mic_music.train.json"})," with the scenes metadata necessary to run the baseline. This location can be changed by setting the ",(0,i.jsx)(n.code,{children:"path.output_music_file"})," parameter."]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"a2-validation-data",children:"A.2 Validation data"}),"\n",(0,i.jsxs)(n.p,{children:["An independent validation set was constructed based on the new MoisesDB dataset [",(0,i.jsx)(n.a,{href:"#refs",children:"2"}),"].\nSongs from MoisesDB were randomly selected to match the number of tracks per genre in the MUSDB18-HQ test set."]}),"\n",(0,i.jsx)(n.admonition,{title:"Genres",type:"info",children:(0,i.jsxs)(n.p,{children:["Note that MUSDB18-HQ and MoisesDB don't share the same genres for all classes.\nWhile MUSDB18-HQ includes a compound genre, ",(0,i.jsx)(n.em,{children:"Pop/Rock"}),", MoisesDB distinguishes between ",(0,i.jsx)(n.em,{children:"Pop"})," and ",(0,i.jsx)(n.em,{children:"Rock"})," genres more explicitly.\nAdditionally, unlike MUSDB18-HQ, MoiseDB does not feature a ",(0,i.jsx)(n.em,{children:"Heavy Metal"})," class."]})}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Genre"}),(0,i.jsx)(n.th,{style:{textAlign:"center"},children:"Validation Set"}),(0,i.jsx)(n.th,{style:{textAlign:"center"},children:"MUSDB18 Test"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Reggae"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"2"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"2"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Rap"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"3"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"3"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Pop"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"20"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"-"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Rock"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"21"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"-"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Pop/Rock"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"-"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"37"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Heavy Metal"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"-"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"4"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Electronic"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"4"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"4"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Total"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"50"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"50"})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:["The validation dataset is available as a downloadable package in the ",(0,i.jsx)(n.a,{href:"../take_part/download",children:"download data and software"})," section.\nNo data generation is required."]}),"\n",(0,i.jsx)(n.p,{children:"Each track was divided into several consecutive 10-second excerpts, ensuring that no silent segments were selected.\nThen, a random Head-Related Transfer Function (HRTF) was applied to each excerpt.\nThis means that two excerpts from the same track will have different pairs of HRTFs applied,\nthus requiring separation models to be robust under varying HRTF conditions and for different songs"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"967 samples"}),"\n",(0,i.jsx)(n.li,{children:"10-second duration"}),"\n",(0,i.jsx)(n.li,{children:"44,100 Hz"}),"\n",(0,i.jsx)(n.li,{children:"16-bit"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Note that for the validation dataset, only two listeners were assigned per scene in the scene_listeners.json file.\nFor more details about the scene_listener metadata file, please refer to section [C.5 Scene-listeners](#C.5 Scene-listeners) below."}),"\n",(0,i.jsx)(n.h3,{id:"a3-evaluation-test-set",children:"A.3 Evaluation (test) set"}),"\n",(0,i.jsx)(n.p,{children:"The evaluation set is based in the MUSDB18-HQ test set (50 tracks)."}),"\n",(0,i.jsx)(n.p,{children:"The MUSDB18-HQ has the following genre distribution:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Genre"}),(0,i.jsx)(n.th,{style:{textAlign:"center"},children:"Tracks"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Reggae"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"2"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Rap"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"3"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Pop/Rock"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"37"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Heavy Metal"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"4"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Electronic"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"4"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Total"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"50"})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"Following the same procedure as the validation set, each track is divided into several consecutive 10-second excerpts,\nensuring that no silent segments are selected. Then, a randomly selected HRTF is applied to each excerpt."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"960 samples"}),"\n",(0,i.jsx)(n.li,{children:"10-second duration"}),"\n",(0,i.jsx)(n.li,{children:"44,100 Hz"}),"\n",(0,i.jsx)(n.li,{children:"16-bit"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"In the evaluation, each scene will be processed for 20 random test listeners."}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsx)(n.p,{children:"The evaluation set only contains the mixture signal. This is to ensure it is not use for refining the systems."})}),"\n",(0,i.jsx)(n.h2,{id:"b-training-augmentation-data",children:"B. Training augmentation data"}),"\n",(0,i.jsx)(n.h3,{id:"b1-new-scenes",children:"B.1 New Scenes"}),"\n",(0,i.jsxs)(n.p,{children:["You can augment the training data by generating more random training scenes.\nFor this, we provide the ",(0,i.jsx)(n.code,{children:"generate_dataset/generate_train_scenes.py"})," script. This script shares the ",(0,i.jsx)(n.code,{children:"config.yaml"})," with\n",(0,i.jsx)(n.code,{children:"generate_dataset/generate_at_mic_musdb18.py"})," script."]}),"\n",(0,i.jsx)(n.p,{children:"To generate more scenes, you need:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Set the parameter ",(0,i.jsx)(n.code,{children:"scene.number_scenes_per_song"})," to the number of the different scenes to generate for each track."]}),"\n",(0,i.jsxs)(n.li,{children:["The default value of scenes per song is ",(0,i.jsx)(n.code,{children:"4"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["This script uses the track name to seed the random generation. This ensures:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"a reproducible scenes' generation."}),"\n",(0,i.jsxs)(n.li,{children:["increasing the number of scenes per song will always result in the 4 scenes provided in the ",(0,i.jsx)(n.strong,{children:"core"})," package plus new scenes."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.li,{children:"Run the script as:"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"python3 generate_train_scenes.py \\\n  path.root=/Volumes/cadenza_data/icassp_2024/ \\\n  scene.number_scenes_per_song=<number greater than 4>\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Additionally, you can change the ",(0,i.jsx)(n.code,{children:"scene_listener.number_listeners_per_scene"})," parameter to set how many listeners pair with the same scene.\nBy default, this parameter is set to ",(0,i.jsx)(n.code,{children:"2"}),"."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"python3 generate_train_scenes.py \\\n  path.root=/Volumes/cadenza_data/icassp_2024/ \\\n  scene_listener.number_listeners_per_scene=<number greater than 2>\n"})}),"\n",(0,i.jsx)(n.admonition,{title:"Consider that ...",type:"warning",children:(0,i.jsxs)(n.p,{children:["Generating new scenes will not preserve the scene_id from the ",(0,i.jsx)(n.strong,{children:"core"})," package. This is because the id is assigned incrementally.\nHowever, this does not have any significance in the process as these scenes are used exclusively for training separation models."]})}),"\n",(0,i.jsx)(n.h3,{id:"b2-augmenting-tracks",children:"B.2 Augmenting tracks"}),"\n",(0,i.jsx)(n.p,{children:"Teams can supplement the training data using the following resources:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Bach10"}),"\n",(0,i.jsx)(n.li,{children:"FMA-small"}),"\n",(0,i.jsx)(n.li,{children:"MedleydB version 1 and version 2"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"We leave the teams to decide how to use these as part of the training of their systems. The supplemental data will need HRTFs applied to them as we did for MUSDB18-HQ.\nNote, 46 songs from MedleydB version 1 are already part of the training set in MUSDB18-HQ."}),"\n",(0,i.jsxs)(s,{children:[(0,i.jsx)("summary",{children:"MUSDB18-HQ already contains 46 tracks from the MedleyDB version 1"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A Classic Education - NightOwl"}),"\n",(0,i.jsx)(n.li,{children:"Aimee Norwich - Child"}),"\n",(0,i.jsx)(n.li,{children:"Alexander Ross - Goodbye Bolero"}),"\n",(0,i.jsx)(n.li,{children:"Alexander Ross - Velvet Curtain"}),"\n",(0,i.jsx)(n.li,{children:"Auctioneer - Our Future Faces"}),"\n",(0,i.jsx)(n.li,{children:"AvaLuna - Waterduct"}),"\n",(0,i.jsx)(n.li,{children:"BigTroubles - Phantom"}),"\n",(0,i.jsx)(n.li,{children:"Celestial Shore - Die For Us"}),"\n",(0,i.jsx)(n.li,{children:"Clara Berry And Wooldog - Air Traffic"}),"\n",(0,i.jsx)(n.li,{children:"Clara Berry And Wooldog - Stella"}),"\n",(0,i.jsx)(n.li,{children:"Clara Berry And Wooldog - Waltz For My Victims"}),"\n",(0,i.jsx)(n.li,{children:"Creepoid - OldTree"}),"\n",(0,i.jsx)(n.li,{children:"Dreamers Of The Ghetto - Heavy Love"}),"\n",(0,i.jsx)(n.li,{children:"Faces On Film - Waiting For Ga"}),"\n",(0,i.jsx)(n.li,{children:"Grants - PunchDrunk"}),"\n",(0,i.jsx)(n.li,{children:"Helado Negro - Mitad Del Mundo"}),"\n",(0,i.jsx)(n.li,{children:"Hezekiah Jones - Borrowed Heart"}),"\n",(0,i.jsx)(n.li,{children:"Hop Along - Sister Cities"}),"\n",(0,i.jsx)(n.li,{children:"Invisible Familiars - Disturbing Wildlife"}),"\n",(0,i.jsx)(n.li,{children:"Lushlife - Toynbee Suite"}),"\n",(0,i.jsx)(n.li,{children:"Matthew Entwistle - Dont You Ever"}),"\n",(0,i.jsx)(n.li,{children:"Meaxic - Take A Step"}),"\n",(0,i.jsx)(n.li,{children:"Meaxic - You Listen"}),"\n",(0,i.jsx)(n.li,{children:"Music Delta - 80s Rock"}),"\n",(0,i.jsx)(n.li,{children:"Music Delta - Beatles"}),"\n",(0,i.jsx)(n.li,{children:"Music Delta - Britpop"}),"\n",(0,i.jsx)(n.li,{children:"Music Delta - Country1"}),"\n",(0,i.jsx)(n.li,{children:"Music Delta - Country2"}),"\n",(0,i.jsx)(n.li,{children:"Music Delta - Disco"}),"\n",(0,i.jsx)(n.li,{children:"Music Delta - Gospel"}),"\n",(0,i.jsx)(n.li,{children:"Music Delta - Grunge"}),"\n",(0,i.jsx)(n.li,{children:"Music Delta - Hendrix"}),"\n",(0,i.jsx)(n.li,{children:"Music Delta - Punk"}),"\n",(0,i.jsx)(n.li,{children:"Music Delta - Reggae"}),"\n",(0,i.jsx)(n.li,{children:"Music Delta - Rock"}),"\n",(0,i.jsx)(n.li,{children:"Music Delta - Rockabilly"}),"\n",(0,i.jsx)(n.li,{children:"Night Panther - Fire"}),"\n",(0,i.jsx)(n.li,{children:"Port St Willow - Stay Even"}),"\n",(0,i.jsx)(n.li,{children:"Secret Mountains - High Horse"}),"\n",(0,i.jsx)(n.li,{children:"Snowmine - Curfews"}),"\n",(0,i.jsx)(n.li,{children:"Steven Clark - Bounty"}),"\n",(0,i.jsx)(n.li,{children:"Strand Of Oaks - Spacestation"}),"\n",(0,i.jsx)(n.li,{children:"Sweet Lights - You Let Me Down"}),"\n",(0,i.jsx)(n.li,{children:"The Districts - Vermont"}),"\n",(0,i.jsx)(n.li,{children:"The Scarlet Brand - Les Fleurs Du Mal"}),"\n",(0,i.jsx)(n.li,{children:"The So So Glos - Emergency"}),"\n"]})]}),"\n",(0,i.jsxs)(n.p,{children:["For more information on augmenting and supplementing the music training data, please see the ",(0,i.jsx)(n.a,{href:"../take_part/rules",children:"rules"}),"."]}),"\n",(0,i.jsx)(n.h2,{id:"c-metadata-information",children:"C. Metadata Information"}),"\n",(0,i.jsx)(n.h3,{id:"c1-listener-characteristics",children:"C.1 Listener characteristics"}),"\n",(0,i.jsxs)(n.p,{children:["We provide metadata characterising the hearing abilities of listeners so the audio signals can be personalised.\nThe quantification of the listeners' hearing is done with left and right audiograms. These measure the threshold at which people can hear a pure-tone sound.\n",(0,i.jsx)(n.a,{href:"/docs/learning_resources/Hearing_impairment/edu_measuring_HI#audiograms",children:"More information on what audiograms are and how they're measured"}),"."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["For training, we provide 83 listener audiograms that were collected for the ",(0,i.jsx)(n.a,{href:"https://claritychallenge.org/",children:"Clarity project"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["For validation, we constructed a new set of 50 listener audiograms from the ",(0,i.jsxs)(n.a,{href:"https://zenodo.org/record/4995261#.Y_3O1HbP2Hu",children:[(0,i.jsx)(n.em,{children:"von Gablenz and Holube (2019)"}),"\ndataset"]}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["For evaluation, we will use a set of 52 listener audiograms use in ",(0,i.jsx)(n.a,{href:"../../cadenza1/cc1_intro",children:"first Cadenza Challenges"})]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Visit ",(0,i.jsx)(n.a,{href:"data_listener",children:"Listener Metadata"})," for more details."]}),"\n",(0,i.jsx)(n.h3,{id:"c2-gains",children:"C.2 Gains"}),"\n",(0,i.jsx)(n.p,{children:"We provide metadata giving the gains to use for rebalancing the mixture. There are 1105 possible combinations created by:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Choosing how many VDBO tracks have their gain altered: 1, 2, or 3."}),"\n",(0,i.jsx)(n.li,{children:"Choosing the gain for those tracks: [-10, -6, -3, 3, 6, 10] dB."}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"In the metadata, this is then reported as the gain for each of the VDBO track. The same set of gains are used for training, validation and evaluation."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{   \n    ...\n    "gain_0007": {    \n        "vocals":  10, # Amplify vocals in 10 dB\n        "drums" :   0,\n        "bass"  :   0,\n        "other" :   0\n    },\n    ...\n    "gain_0138": {\n        "vocals":   0,\n        "drums" : -10, # Attenuate drums in 10 dB\n        "bass"  :   6, # Amplify bass in 6 dB\n        "other" :   0\n    },\n    ...\n    "gain_0381": {\n        "vocals":   3, # Amplify vocals in 3 dB\n        "drums" :  10, # Amplify drums in 10 dB\n        "bass"  :  -6, # Attenuate bass in 6 dB\n        "other" :   0\n    },\n    ...\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"c3-head-and-loudspeaker-positions",children:"C.3 Head and loudspeaker positions"}),"\n",(0,i.jsxs)(n.p,{children:["We provide metadata indicating the subject head and loudspeaker positions.\nThis set corresponds to a subset of the OlHeaD-HRTF [",(0,i.jsx)(n.a,{href:"#refs",children:"2"}),"] dataset.\nThere are 16 subjects and 9 possible angles combinations."]}),"\n",(0,i.jsxs)(s,{children:[(0,i.jsx)("summary",{children:"Left and right HRTFs angles combination"}),(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Angle Left"}),(0,i.jsx)(n.th,{children:"Angle Right"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"-22.5"}),(0,i.jsx)(n.td,{children:"22.5"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"-22.5"}),(0,i.jsx)(n.td,{children:"30.0"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"-22.5"}),(0,i.jsx)(n.td,{children:"37.5"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"-30.0"}),(0,i.jsx)(n.td,{children:"22.5"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"-30.0"}),(0,i.jsx)(n.td,{children:"30.0"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"-30.0"}),(0,i.jsx)(n.td,{children:"37.5"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"-37.5"}),(0,i.jsx)(n.td,{children:"22.5"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"-37.5"}),(0,i.jsx)(n.td,{children:"30.0"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"-37.5"}),(0,i.jsx)(n.td,{children:"37.5"})]})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"The data is provided in a JSON file:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{\n    "hlp_0001": {\n        "subject"    : "VP_E1",\n        "left_angle" : -37.5,\n        "right_angle": 22.5,\n        "mic"        : "BTE_fr"\n    },\n    ...\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"c4-scenes",children:"C.4 Scenes"}),"\n",(0,i.jsx)(n.p,{children:"The scene metadata is provided in a JSON file with the following structure:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{\n    "scene_10001": {\n        "music" : "A Classic Education - NightOwl",\n        "gain"  : "gain_0639",\n        "head_loudspeaker_positions": "hlp_0056"\n    },\n    ...\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"c5-scene-listeners",children:"C.5 Scene-listeners"}),"\n",(0,i.jsx)(n.p,{children:"The scene-listener metadata is provided in a JSON file with the following structure:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{\n    "scene_10001": [\n        "L0066",\n        "L0057"\n    ],\n    ...\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"c6-musdb18-hq",children:"C.6 MUSDB18-HQ"}),"\n",(0,i.jsx)(n.p,{children:"The MUSDB18-HQ metadata is provided in a single JSON file per dataset."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'[\n    {\n        "Track Name" : "A Classic Education - NightOwl",\n        "Genre"      : "Singer/Songwriter",\n        "Source"     : "MedleyDB",\n        "License"    : "CC BY-NC-SA",\n        "Split"      : "train"\n    },\n    ...\n]\n'})}),"\n",(0,i.jsx)(n.h3,{id:"c7-signals-at-hearing-aid-microphones",children:"C.7 Signals at hearing aid microphones"}),"\n",(0,i.jsx)(n.p,{children:"The at_the_mic metadata is provided in a JSON file with the following structure.:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{\n    "A Classic Education - NightOwl-hlp_0056": {\n        "Track Name" : "A Classic Education - NightOwl-hlp_0056",\n        "Split"      : "valid",\n        "Path"       : "valid/A Classic Education - NightOwl-hlp_0056"\n    },\n    ...\n}\n'})}),"\n",(0,i.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,i.jsx)("a",{name:"refs"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"[1]"})," Rafii, Z., Liutkus, A., St\xf6ter, F.-R., Mimilakis, S. I., and Bittner, R. (2019). MUSDB18-HQ - an Uncompressed Version of MUSDB18. [Dataset]. doi:10.5281/zenodo.3338373",(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.strong,{children:"[2]"})," F. Denk, S.M.A. Ernst, S.D. Ewert and B. Kollmeier, (2018): Adapting hearing devices to the individual ear acoustics: Database and target response correction functions for various device styles. Trends in Hearing, vol 22, p. 1-19. DOI:10.1177/2331216518779313",(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.strong,{children:"[3]"})," Pereira, I., Ara\xfajo, F., Korzeniowski, F., & Vogl, R. (2023). Moisesdb: A dataset for source separation beyond 4-stems. arXiv preprint arXiv:2307.15913"]})]})}function o(e={}){const{wrapper:n}={...(0,a.a)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}}}]);
/*! For license information please see 05f53a8a.f1038edd.js.LICENSE.txt */
(self.webpackChunkcadenza=self.webpackChunkcadenza||[]).push([[4404,7596],{73005:(e,n,t)=>{"use strict";t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>u,frontMatter:()=>o,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"cadenza1/cc1_summary_task1","title":"Summary Task 1","description":"[//]: # (","source":"@site/docs/cadenza1/cc1_summary_task1.md","sourceDirName":"cadenza1","slug":"/cadenza1/cc1_summary_task1","permalink":"/docs/cadenza1/cc1_summary_task1","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"cc1_summary_task1","title":"Summary Task 1","sidebar_label":"Summary Task 1","sidebar_position":2},"sidebar":"tutorialSidebar_cad1","previous":{"title":"Results","permalink":"/docs/cadenza1/cc1_results"},"next":{"title":"Summary Task 2","permalink":"/docs/cadenza1/cc1_summary_task2"}}');var i=t(74848),r=t(28453),a=t(41306);t(28770);const o={id:"cc1_summary_task1",title:"Summary Task 1",sidebar_label:"Summary Task 1",sidebar_position:2},l=void 0,c={},d=[{value:"1. Description of the Problem",id:"1-description-of-the-problem",level:2},{value:"1.1 Enhancement Stage",id:"11-enhancement-stage",level:3},{value:"1.1.1 Dataset",id:"111-dataset",level:4},{value:"1.1.2 Output",id:"112-output",level:4},{value:"1.2 Evaluation Stage",id:"12-evaluation-stage",level:3},{value:"2. Software",id:"2-software",level:2},{value:"3. Baselines",id:"3-baselines",level:2}];function h(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h2,{id:"1-description-of-the-problem",children:"1. Description of the Problem"}),"\n",(0,i.jsx)(n.p,{children:"A person with a hearing loss is listening to music via headphones. They're not using their hearing aids."}),"\n",(0,i.jsx)(n.p,{children:"The machine learning task is to decompose a stereo song into a VDBO (vocal, drums, bass and other) representation.\nThis then allows a personalised remixing for the listener that has better audio quality.\nFor example, for some music you might amplify the vocals to improve the audibility of the lyrics."}),"\n",(0,i.jsxs)(n.p,{children:["As shown in Figure [",(0,i.jsx)(n.a,{href:"#fig1",children:"1"}),"], the system is split into two stages; the ",(0,i.jsx)(n.em,{children:"enhancement"})," and ",(0,i.jsx)(n.em,{children:"evaluation"}),"."]}),"\n",(0,i.jsxs)("figure",{id:"fig1",children:[(0,i.jsx)("img",{width:"800",src:(0,a.Ay)("/img/headphone_simple_v3.png")}),(0,i.jsx)("figcaption",{children:"Figure 1, The baseline for the headphone listening scenario. For simplicity, not all signal paths are shown."})]}),"\n",(0,i.jsx)(n.h3,{id:"11-enhancement-stage",children:"1.1 Enhancement Stage"}),"\n",(0,i.jsx)(n.admonition,{type:"info",children:(0,i.jsxs)(n.p,{children:["You can adapt and modify the baseline ",(0,i.jsx)(n.strong,{children:"enhancement"})," script or make your own script."]})}),"\n",(0,i.jsxs)(n.p,{children:["Your task is to decompose a stereo music signal and produce 8 mono signals or stems corresponding to the\nright and left ",(0,i.jsx)(n.code,{children:"vocal"}),", ",(0,i.jsx)(n.code,{children:"drums"}),", ",(0,i.jsx)(n.code,{children:"bass"})," and ",(0,i.jsx)(n.code,{children:"other"})," (VDBO), and produce one stereo signal corresponding to a\nremix signal optimised for a target listener.\nFor this, you will have access to relevant datasets that will allow you to explore different approaches to separate the music and/or to remix the signals."]}),"\n",(0,i.jsx)(n.h4,{id:"111-dataset",children:"1.1.1 Dataset"}),"\n",(0,i.jsx)(n.p,{children:"In the enhancement stage, you have access to:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Full length songs from MUSDB18-HQ dataset."}),"\n",(0,i.jsx)(n.li,{children:"Music data for augmentation, if needed."}),"\n",(0,i.jsxs)(n.li,{children:["Listeners characteristics (audiograms). ",(0,i.jsx)(n.a,{href:"Data/cc1_data_listener",children:"Listener Data"})]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Please refer to ",(0,i.jsx)(n.a,{href:"Data/cc1_data_overview_headphone",children:"task 1 data page"})," and\nthe ",(0,i.jsx)(n.a,{href:"https://github.com/claritychallenge/clarity/tree/main/recipes/cad1/task1/baseline",children:"baseline readme"})," for details."]}),"\n",(0,i.jsxs)(n.p,{children:["To download the datasets, please visit ",(0,i.jsx)(n.a,{href:"Take%20part/cc1_download#21-task-1---headphones",children:"download data and software"}),"."]}),"\n",(0,i.jsx)(n.h4,{id:"112-output",children:"1.1.2 Output"}),"\n",(0,i.jsx)(n.p,{children:"The output of this stage are:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Eight stems corresponding to the left and right vocal, bass, drums and other stems.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Sample rate = 24000 Hz"}),"\n",(0,i.jsx)(n.li,{children:"Precision: 16bit integer"}),"\n",(0,i.jsx)(n.li,{children:"Compressed using FLAC"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["One stereo remixed signal","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Sample rate = 32000 Hz"}),"\n",(0,i.jsx)(n.li,{children:"Precision: 16bit integer"}),"\n",(0,i.jsx)(n.li,{children:"Compressed using FLAC"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["For more details about the format of the submission, please refer to the ",(0,i.jsx)(n.a,{href:"Take%20part/cc1_submission",children:"submission"})," webpage."]}),"\n",(0,i.jsx)(n.admonition,{title:"Note",type:"caution",children:(0,i.jsx)(n.p,{children:"The responsibility for the final remixed signal level is yours.\nIt\u2019s worth bearing in mind that should your signals overall seem too loud to be comfortable to a participant,\nthey may well turn down the volume themselves. Also, there may be clipping in the evaluation block in some tasks\nif the processed signals are too large."})}),"\n",(0,i.jsx)(n.h3,{id:"12-evaluation-stage",children:"1.2 Evaluation Stage"}),"\n",(0,i.jsx)(n.admonition,{title:"Warning",type:"danger",children:(0,i.jsxs)(n.p,{children:["You are not allowed to change the ",(0,i.jsx)(n.strong,{children:"evaluation"})," script provided in the baseline.\nYour output signals with be scored using this script."]})}),"\n",(0,i.jsxs)(n.p,{children:["The evaluation stage is a common stage for all submissions.\nAs shown in Figure [",(0,i.jsx)(n.a,{href:"#fig1",children:"1"}),"], the evaluation takes the reference stem signals, i.e., the eight reference stems,\nand the eight processed stems and computes the eight HAAQI scores."]}),"\n",(0,i.jsxs)(n.p,{children:["To learn more about HAAQI, please refer to our ",(0,i.jsx)(n.a,{href:"../learning_resources/Hearing_aid_processing/edu_HAP_HA_processed_speech",children:"Learning Resources"}),"\nand to our Python ",(0,i.jsx)(n.a,{href:"https://github.com/claritychallenge/clarity/blob/cad1task1-baseline2/clarity/evaluator/haaqi/haaqi.py",children:"HAAQI implementation"}),"."]}),"\n",(0,i.jsx)(n.p,{children:"The output of the evaluation stage is a CSV file with all the HAAQI scores."}),"\n",(0,i.jsx)(n.h2,{id:"2-software",children:"2. Software"}),"\n",(0,i.jsxs)(n.p,{children:["All the necessary software to run the recipes and make your own submission is available on our ",(0,i.jsx)(n.a,{href:"https://github.com/claritychallenge/clarity",children:"Clarity-Cadenza\nGitHub repository"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:["The official code for the first challenge was released in version ",(0,i.jsx)(n.code,{children:"v0.3.4"}),".\nTo avoid any conflict, we highly recommend for you to work using version v0.3.4 and\nnot with the code from the ",(0,i.jsx)(n.code,{children:"main"})," branch. To install this version:"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Download the files of the release v0.3.4 from:\n",(0,i.jsx)(n.a,{href:"https://github.com/claritychallenge/clarity/releases/tag/v0.3.4",children:"https://github.com/claritychallenge/clarity/releases/tag/v0.3.4"})]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Clone the repository and checkout version v0.3.4"}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"git clone https://github.com/claritychallenge/clarity.git\ngit checkout tags/v0.3.4\n"})}),"\n",(0,i.jsxs)(n.ol,{start:"3",children:["\n",(0,i.jsx)(n.li,{children:"Install pyclarity from PyPI as:"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"pip install pyclarity==0.3.4\n"})}),"\n",(0,i.jsx)(n.h2,{id:"3-baselines",children:"3. Baselines"}),"\n",(0,i.jsxs)(n.p,{children:["In the ",(0,i.jsx)(n.a,{href:"https://github.com/claritychallenge/clarity",children:"Clarity/Cadenza GitHub repository"}),", we provide two baselines.\nBoth baseline systems work in a similar way. Using a music source separation model, the systems\ndecompose the music into the target eight stems. Both models were trained exclusively on MUSDB18-HQ training set and no\nextra data was used for augmentation."]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"Demucs"}),": This baseline system uses the ",(0,i.jsx)(n.code,{children:"Hybrid Demucs"})," model. This is a time-domain-based model."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"Open-UnMix"}),": This baseline system uses the ",(0,i.jsx)(n.code,{children:"umxhq"})," model from Open-UnMix. This is a spectrogram-based model."]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Please, visit the ",(0,i.jsx)(n.a,{href:"https://github.com/claritychallenge/clarity/tree/cad1task1-baseline2/recipes/cad1/task1/baseline",children:"baseline on the GitHub webpage"}),"\nand ",(0,i.jsx)(n.a,{href:"Software/cc1_baseline#1-task-1-headphones",children:"Baseline"})," links to read more about the baselines and learn how to run them."]})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},28770:(e,n,t)=>{"use strict";t.d(n,{CU:()=>a});var s=t(96540),i="https://platform.twitter.com/widgets.js",r="createTimeline",a=function(e){var n=s.useRef(null),a=s.useState(!0),o=a[0],l=a[1];return s.useEffect((function(){var s=!0;return t(62491)(i,"twitter-embed",(function(){if(window.twttr){if(s){if(!window.twttr.widgets[r])return void console.error("Method "+r+" is not present anymore in twttr.widget api");var t=function(){var t,s,i=Object.assign({},e.options);return null!=e&&e.autoHeight&&(i.height=null===(t=n.current)||void 0===t||null===(s=t.parentNode)||void 0===s?void 0:s.offsetHeight),i=Object.assign({},i,{theme:null==e?void 0:e.theme,linkColor:null==e?void 0:e.linkColor,borderColor:null==e?void 0:e.borderColor,lang:null==e?void 0:e.lang,tweetLimit:null==e?void 0:e.tweetLimit,ariaPolite:null==e?void 0:e.ariaPolite})}();t=function(n){return n.chrome="",e.noHeader&&(n.chrome=n.chrome+" noheader"),e.noFooter&&(n.chrome=n.chrome+" nofooter"),e.noBorders&&(n.chrome=n.chrome+" noborders"),e.noScrollbar&&(n.chrome=n.chrome+" noscrollbar"),e.transparent&&(n.chrome=n.chrome+" transparent"),n}(t),window.twttr.widgets[r]({sourceType:e.sourceType,screenName:e.screenName,userId:e.userId,ownerScreenName:e.ownerScreenName,slug:e.slug,id:e.id||e.widgetId,url:e.url},null==n?void 0:n.current,t).then((function(n){l(!1),e.onLoad&&e.onLoad(n)}))}}else console.error("Failure to load window.twttr, aborting load")})),function(){s=!1}}),[]),s.createElement(s.Fragment,null,o&&s.createElement(s.Fragment,null,e.placeholder),s.createElement("div",{ref:n}))}},62491:(e,n,t)=>{var s,i,r;r=function(){var e,n,t=document,s=t.getElementsByTagName("head")[0],i="push",r="readyState",a="onreadystatechange",o={},l={},c={},d={};function h(e,n){for(var t=0,s=e.length;t<s;++t)if(!n(e[t]))return!1;return 1}function u(e,n){h(e,(function(e){return n(e),1}))}function m(n,t,s){n=n[i]?n:[n];var r=t&&t.call,a=r?t:s,g=r?n.join(""):t,f=n.length;function x(e){return e.call?e():o[e]}function j(){if(! --f)for(var e in o[g]=1,a&&a(),c)h(e.split("|"),x)&&!u(c[e],x)&&(c[e]=[])}return setTimeout((function(){u(n,(function n(t,s){return null===t?j():(s||/^https?:\/\//.test(t)||!e||(t=-1===t.indexOf(".js")?e+t+".js":e+t),d[t]?(g&&(l[g]=1),2==d[t]?j():setTimeout((function(){n(t,!0)}),0)):(d[t]=1,g&&(l[g]=1),void p(t,j)))}))}),0),m}function p(e,i){var o,l=t.createElement("script");l.onload=l.onerror=l[a]=function(){l[r]&&!/^c|loade/.test(l[r])||o||(l.onload=l[a]=null,o=1,d[e]=2,i())},l.async=1,l.src=n?e+(-1===e.indexOf("?")?"?":"&")+n:e,s.insertBefore(l,s.lastChild)}return m.get=p,m.order=function(e,n,t){!function s(i){i=e.shift(),e.length?m(i,s):m(i,n,t)}()},m.path=function(n){e=n},m.urlArgs=function(e){n=e},m.ready=function(e,n,t){e=e[i]?e:[e];var s,r=[];return!u(e,(function(e){o[e]||r[i](e)}))&&h(e,(function(e){return o[e]}))?n():(s=e.join("|"),c[s]=c[s]||[],c[s][i](n),t&&t(r)),m},m.done=function(e){m([null],e)},m},e.exports?e.exports=r():void 0===(i="function"==typeof(s=r)?s.call(n,t,n,e):s)||(e.exports=i)},28453:(e,n,t)=>{"use strict";t.d(n,{R:()=>a,x:()=>o});var s=t(96540);const i={},r=s.createContext(i);function a(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);
"use strict";(self.webpackChunkcadenza=self.webpackChunkcadenza||[]).push([[8690],{57049:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>c,contentTitle:()=>l,default:()=>p,frontMatter:()=>a,metadata:()=>o,toc:()=>h});var i=n(85893),t=n(11151),r=n(79524);const a={id:"baseline",title:"Baseline",sidebar_label:"Baseline",sidebar_position:7.1},l=void 0,o={id:"icassp_2024/software/baseline",title:"Baseline",description:"Challenge entrants are supplied with a fully functioning baseline system.",source:"@site/docs/icassp_2024/software/icassp2024_baseline.mdx",sourceDirName:"icassp_2024/software",slug:"/icassp_2024/software/baseline",permalink:"/docs/icassp_2024/software/baseline",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:7.1,frontMatter:{id:"baseline",title:"Baseline",sidebar_label:"Baseline",sidebar_position:7.1},sidebar:"tutorialSidebar_icassp2024",previous:{title:"Software",permalink:"/docs/category/software-1"},next:{title:"Core Software",permalink:"/docs/icassp_2024/software/core_software"}},c={},h=[{value:"The <strong>Pre-Process</strong> blocks",id:"the-pre-process-blocks",level:3},{value:"The <strong>Enhancement</strong> block",id:"the-enhancement-block",level:3},{value:"The <strong>Evaluation</strong> block",id:"the-evaluation-block",level:3},{value:"Baseline Scores",id:"baseline-scores",level:3},{value:"References",id:"references",level:2}];function d(e){const s={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(s.p,{children:"Challenge entrants are supplied with a fully functioning baseline system."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.a,{href:"#fig2",children:"Figure 2"})," shows a detailed schematic of the baseline system:"]}),"\n",(0,i.jsx)("div",{style:{textAlign:"center"},children:(0,i.jsxs)("figure",{id:"fig2",children:[(0,i.jsx)("img",{width:"900",src:(0,r.Z)("/img/icassp_2024/task_diagram_hrtf.png")}),(0,i.jsx)("figcaption",{children:"Figure 2, Detailed schematic of the baseline system."})]})}),"\n",(0,i.jsx)(s.p,{children:"where:"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"Green boxes represent audio signals."}),"\n",(0,i.jsx)(s.li,{children:"Blue boxes represent operations applied to the audio signals."}),"\n",(0,i.jsx)(s.li,{children:"Blue database box is the anechoic HRTF dataset (audio signals)."}),"\n",(0,i.jsx)(s.li,{children:"Red database box is the listener characteristics dataset (metadata information)."}),"\n",(0,i.jsx)(s.li,{children:"Yellow database box is the gains dataset (metadata information)."}),"\n",(0,i.jsx)(s.li,{children:"White 'Weight and sum' box is the downmix operation."}),"\n",(0,i.jsx)(s.li,{children:"Solid lines are signals transferred from one state of process to the next."}),"\n",(0,i.jsx)(s.li,{children:"Dashed lines are metadata information."}),"\n"]}),"\n",(0,i.jsxs)(s.h3,{id:"the-pre-process-blocks",children:["The ",(0,i.jsx)(s.strong,{children:"Pre-Process"})," blocks"]}),"\n",(0,i.jsxs)(s.p,{children:['The system starts by applying HRTFs to the music of MUSDB18-HQ dataset, simulating the music as it is picked up by the hearing aids microphones.\nThis stage is illustrated by the "pre-process enhancement" and "pre-process evaluation" boxes. However, in practice both boxes\ncorrespond to the output of the ',(0,i.jsx)(s.code,{children:"generate_at_mic_musdb18.py"})," script."]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["First, it takes the ",(0,i.jsx)(s.code,{children:"Scene"})," details:","\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"MUSDB18-HQ music (mixture, vocal, drums, bass, other)."}),"\n",(0,i.jsx)(s.li,{children:"Subject head and loudspeaker-position (HRTFs)."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["It applies the HRTFs to the left and right side of all signals (mixture and VDBO components) [",(0,i.jsx)(s.a,{href:"#fig2",children:"Figure 2"}),"]"]}),"\n",(0,i.jsx)(s.li,{children:'The mixture with HRTF applied corresponds to the output of the "pre-process enhancement" block.'}),"\n",(0,i.jsx)(s.li,{children:'The VDBO signals with HRTF applied correspond to the output of the "pre-process evaluation" block.'}),"\n"]}),"\n",(0,i.jsx)("div",{style:{textAlign:"center"},children:(0,i.jsxs)("figure",{id:"fig2",children:[(0,i.jsx)("img",{width:"500",src:(0,r.Z)("/img/icassp_2024/cross-talk-hrtf.png")}),(0,i.jsx)("figcaption",{children:"Figure 3, The scenario."})]})}),"\n",(0,i.jsxs)(s.h3,{id:"the-enhancement-block",children:["The ",(0,i.jsx)(s.strong,{children:"Enhancement"})," block"]}),"\n",(0,i.jsx)(s.p,{children:"The enhancement takes a mixture signal as it is picked up by the hearing aids microphones and attempts to output a personalized rebalanced stereo rendition of the music."}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:'First, it takes stereo tracks ("mixture at the hearing aid mics") and demixes them into their VDBO (vocal, drums, bass and other) representation. This is done by using an out-of-the-box audio source separation system.'}),"\n",(0,i.jsx)(s.li,{children:"Then, using the gains provided, the music is downmixed to stereo after changing the level of the different elements of the music."}),"\n",(0,i.jsx)(s.li,{children:"Next, the downmixed signal is normalised to match the LUFS level of the input mixture."}),"\n",(0,i.jsx)(s.li,{children:"NAL-R amplification is applied to the normalised downmixed signal, allowing for a personalised amplification for the listener using a standard hearing aid algorithm."}),"\n",(0,i.jsxs)(s.li,{children:["This amplified signal is the output of the system: ",(0,i.jsx)(s.code,{children:"Processed signal"})]}),"\n"]}),"\n",(0,i.jsxs)(s.h3,{id:"the-evaluation-block",children:["The ",(0,i.jsx)(s.strong,{children:"Evaluation"})," block"]}),"\n",(0,i.jsx)(s.p,{children:"The evaluation generates the reference and processed signals and computes the HAAQI score."}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"First, it takes the VDBO signals at the hearing aid microphones (these are the VDBO components provided by MUSDB18-HQ with the HRTF applied to them) and remixes the signals using the same gains as applied in the enhancement."}),"\n",(0,i.jsx)(s.li,{children:'Then, it normalises the remix to the same LUFS level as the "mixture at the hearing aid mics".'}),"\n",(0,i.jsx)(s.li,{children:"Next, it applies the NAL-R amplification."}),"\n",(0,i.jsxs)(s.li,{children:["This process results in the ",(0,i.jsx)(s.code,{children:"Reference signal"}),' for HAAQI, which simulates a "listener preferred mixture". The reference signal corresponds to an ideal rebalanced signal when we have access to the clean VDBO components.']}),"\n",(0,i.jsxs)(s.li,{children:["As HAAQI is an intrusive metric, the score is computed by comparing the ",(0,i.jsx)(s.code,{children:"Processed signal"})," (downmixed music) with the ",(0,i.jsx)(s.code,{children:"Reference signal"}),", focussing on changes to time-frequency envelope modulation, temporal fine structure and long-term spectrum."]}),"\n"]}),"\n",(0,i.jsx)(s.admonition,{title:"Note",type:"info",children:(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["In the Enhancement and Evaluation blocks, we apply a loudness normalisation (in ",(0,i.jsx)(s.a,{href:"https://www.izotope.com/en/learn/what-are-lufs.html",children:"LUFS"}),") after applying the gains.\nThis is to keep the loudness of the remix at the same levels as the mixture at the hearing aid mics."]}),"\n",(0,i.jsx)(s.li,{children:"As required by HAAQI, we resample both the reference and processed signal before computing the score."}),"\n"]})}),"\n",(0,i.jsx)(s.h3,{id:"baseline-scores",children:"Baseline Scores"}),"\n",(0,i.jsxs)(s.p,{children:["Two baseline systems are proposed by employing two out-of-the-box audio source separation systems in the ",(0,i.jsx)(s.code,{children:"enhancement"})," block."]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["Hybrid Demucs [",(0,i.jsx)(s.a,{href:"#refs",children:"2"}),"] distributed on TorchAudio"]}),"\n",(0,i.jsxs)(s.li,{children:["Open-Unmix [",(0,i.jsx)(s.a,{href:"#refs",children:"3"}),"]  distributed through Pytorch hub."]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"The average HAAQI scores are:"}),"\n",(0,i.jsxs)(s.table,{children:[(0,i.jsx)(s.thead,{children:(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.th,{children:"System"}),(0,i.jsx)(s.th,{style:{textAlign:"center"},children:"Left HAAQI"}),(0,i.jsx)(s.th,{style:{textAlign:"center"},children:"Right HAAQI"}),(0,i.jsx)(s.th,{style:{textAlign:"center"},children:"Overall"})]})}),(0,i.jsxs)(s.tbody,{children:[(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"Demucs"}),(0,i.jsx)(s.td,{style:{textAlign:"center"},children:"0.6690"}),(0,i.jsx)(s.td,{style:{textAlign:"center"},children:"0.6665"}),(0,i.jsx)(s.td,{style:{textAlign:"center"},children:"0.6677"})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"OpenUnmix"}),(0,i.jsx)(s.td,{style:{textAlign:"center"},children:"0.5986"}),(0,i.jsx)(s.td,{style:{textAlign:"center"},children:"0.5940"}),(0,i.jsx)(s.td,{style:{textAlign:"center"},children:"0.5963"})]})]})]}),"\n",(0,i.jsx)(s.h2,{id:"references",children:"References"}),"\n",(0,i.jsx)("a",{name:"refs"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"[1]"})," Kates, J.M.  and Arehart, K.H., 2016. The Hearing-Aid Audio Quality Index (HAAQI), in IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 24, no. 2, pp. 354-365, doi: 10.1109/TASLP.2015.2507858"]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"[2]"}),' D\xe9fossez, A. "Hybrid Spectrogram and Waveform Source Separation". Proceedings of the ISMIR 2021 Workshop on Music Source Separation. doi:10.48550/arXiv.2111.03600']}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"[3]"}),' St\xf6ter, F. R., Liutkus, A., Ito, N., Nakashika, T., Ono, N., & Mitsufuji, Y. (2019). "Open-Unmix: A Reference Implementation for Music Source Separation". Journal of Open Source Software, 4(41), 1667. doi:10.21105/joss.01667']})]})}function p(e={}){const{wrapper:s}={...(0,t.a)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},11151:(e,s,n)=>{n.d(s,{Z:()=>l,a:()=>a});var i=n(67294);const t={},r=i.createContext(t);function a(e){const s=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function l(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),i.createElement(r.Provider,{value:s},e.children)}}}]);
"use strict";(self.webpackChunkcadenza=self.webpackChunkcadenza||[]).push([[3820],{86306:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>d,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"cadenza1/Data/cc1_data_listener","title":"Listener metadata","description":"The same listener data is used for Task 1 and 2. We have provided metadata characterising the hearing abilities of the listeners, so the audio signals you","source":"@site/docs/cadenza1/Data/cc1_data_listener.md","sourceDirName":"cadenza1/Data","slug":"/cadenza1/Data/cc1_data_listener","permalink":"/docs/cadenza1/Data/cc1_data_listener","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5.3,"frontMatter":{"id":"cc1_data_listener","title":"Listener metadata","sidebar_label":"Listener data","sidebar_position":5.3},"sidebar":"tutorialSidebar_cad1","previous":{"title":"Task2 car","permalink":"/docs/cadenza1/Data/cc1_data_overview_car"},"next":{"title":"Listening tests","permalink":"/docs/cadenza1/Data/cc1_listening_tests"}}');var r=n(74848),i=n(28453);n(41306);const s={id:"cc1_data_listener",title:"Listener metadata",sidebar_label:"Listener data",sidebar_position:5.3},o=void 0,d={},l=[{value:"Data file formats and naming conventions",id:"data-file-formats-and-naming-conventions",level:2}];function c(e){const a={a:"a",code:"code",h2:"h2",p:"p",pre:"pre",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(a.p,{children:["The same listener data is used for Task 1 and 2. We have provided metadata characterising the hearing abilities of the listeners, so the audio signals you\ngenerate can be individualised. The same types of data are available for training and development. More on ",(0,r.jsx)(a.a,{href:"../../learning_resources/Hearing_impairment/edu_HI_general",children:"hearing loss"})," and ",(0,r.jsx)(a.a,{href:"../../learning_resources/Hearing_impairment/edu_measuring_HI",children:"how it is measured"}),"."]}),"\n",(0,r.jsxs)(a.p,{children:["For training, we will use the same 83 ",(0,r.jsx)(a.a,{href:"../../learning_resources/Hearing_impairment/edu_measuring_HI",children:"audiograms"})," from the ",(0,r.jsx)(a.a,{href:"https://claritychallenge.org/",children:"Clarity project"}),"."]}),"\n",(0,r.jsxs)(a.p,{children:["We constructed a new set of listeners to separate the training from the development listeners.\nThe development ",(0,r.jsx)(a.a,{href:"../../learning_resources/Hearing_impairment/edu_measuring_HI",children:"audiograms"})," are a filtered, pseudo-random, selection from the\n",(0,r.jsx)(a.a,{href:"https://zenodo.org/record/4995261#.Y_3O1HbP2Hu",children:"von Gablenz and Holube (2019) dataset"}),".\nWe first filtered the audiograms to better-ear 4-frequency hearing loss between 25 and 60 dB.\nThen, we divided the data into BEA bands of 20-29, 30-39, 40-49 and 50-59 dB, and randomly chose from each\nband the necessary number of audiograms to give the same distribution per band as in\nthe original Clarity dataset (namely 11, 37, 34 and 18). This gave an unequal male",":female"," distribution\n(63 to 37), so 13 males were then randomly selected and replaced by females with the same BEA.\nOf the 100 audiograms, only 50 (25 per gender) were randomly selected to be part of the development set."]}),"\n",(0,r.jsx)(a.p,{children:"A panel of hearing-aided listeners will be recruited for evaluation. They will be experienced bilateral\nhearing-aid users: they use two hearing aids but the hearing loss may be asymmetrical. The average pure\ntone air-conduction hearing loss will be between 25 and about 60 dB in the better ear."}),"\n",(0,r.jsxs)(a.p,{children:["The quantification of the listeners' hearing is done with left and right pure tone air-conduction audiograms.\nThese measure the threshold at which people can hear a pure-tone sound. ",(0,r.jsx)(a.a,{href:"/docs/learning_resources/Hearing_impairment/edu_measuring_HI#audiograms",children:"More information"}),"."]}),"\n",(0,r.jsx)(a.h2,{id:"data-file-formats-and-naming-conventions",children:"Data file formats and naming conventions"}),"\n",(0,r.jsx)(a.p,{children:"Audiograms data is stored in a JSON file per dataset with the following format."}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-json",children:'{\n    "L0001": {\n        "name": "L0001",\n        "audiogram_cfs": [250, 500, 1000, 2000, 3000, 4000, 6000, 8000],\n        "audiogram_levels_l": [10, 10, 20, 30, 40, 55, 55, 60],\n        "audiogram_levels_r": [ ... ],\n    },\n    "L0002": {\n        ...\n    },\n    ...\n}\n'})})]})}function h(e={}){const{wrapper:a}={...(0,i.R)(),...e.components};return a?(0,r.jsx)(a,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},28453:(e,a,n)=>{n.d(a,{R:()=>s,x:()=>o});var t=n(96540);const r={},i=t.createContext(r);function s(e){const a=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function o(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),t.createElement(i.Provider,{value:a},e.children)}}}]);
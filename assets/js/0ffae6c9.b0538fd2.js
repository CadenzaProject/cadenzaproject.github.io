"use strict";(self.webpackChunkcadenza=self.webpackChunkcadenza||[]).push([[255],{88770:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>r,contentTitle:()=>o,default:()=>u,frontMatter:()=>s,metadata:()=>l,toc:()=>c});var i=a(74848),t=a(28453);a(85176);const s={id:"evaluation",title:"Evaluation Set",sidebar_label:"Evaluation",sidebar_position:4.7},o=void 0,l={id:"cadenza2/evaluation",title:"Evaluation Set",description:"1. Task 1 - Lyric Intelligibility",source:"@site/docs/cadenza2/cc2_evaluation.md",sourceDirName:"cadenza2",slug:"/cadenza2/evaluation",permalink:"/docs/cadenza2/evaluation",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:4.7,frontMatter:{id:"evaluation",title:"Evaluation Set",sidebar_label:"Evaluation",sidebar_position:4.7}},r={},c=[{value:"1. Task 1 - Lyric Intelligibility",id:"1-task-1---lyric-intelligibility",level:2},{value:"1.1 Evaluation Music",id:"11-evaluation-music",level:3},{value:"1.2 Submission",id:"12-submission",level:3},{value:"2. Task 2 - Rebalancing Classical Music",id:"2-task-2---rebalancing-classical-music",level:2},{value:"2.1 Evaluation Music",id:"21-evaluation-music",level:3},{value:"References",id:"references",level:2}];function d(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h2,{id:"1-task-1---lyric-intelligibility",children:"1. Task 1 - Lyric Intelligibility"}),"\n",(0,i.jsx)(n.p,{children:"The evaluation package contains all the audios and metadata necessary to run process the signals."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"cadenza_cad2_task1_evaluation.v1_0.tar.gz"})," ",(0,i.jsx)(n.strong,{children:"[1.7 GB]"})," - audio and metadata evaluation."]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"11-evaluation-music",children:"1.1 Evaluation Music"}),"\n",(0,i.jsx)(n.p,{children:"The evaluation set is derived from the MUSDB18 test split and the English subset of the JamendoLyrics datasets.\nFor MUSDB18, the test split contains 50 tracks, but only 39 were included in our evaluation.\nThe remaining 11 tracks were excluded for specific reasons: five are not in English, three have vocals but no lyrics, one contains potentially offensive lyrics, and two feature styles that might disturb our listener panel.\nFrom the JamendoLyrics dataset, 18 of the 20 English tracks were included. One track was excluded due to offensive lyrics, and another could not be properly segmented."}),"\n",(0,i.jsx)(n.p,{children:"The evaluation set focuses exclusively on verse sections of songs.\nChoruses were excluded because they exhibit distinct statistical characteristics, which complicate comparisons with verses.\nAdditionally, choruses are generally easier to understand, as they are designed to be simpler and more memorable."}),"\n",(0,i.jsxs)(n.p,{children:["To construct the evaluation set, we first employed the ",(0,i.jsx)(n.a,{href:"https://github.com/mir-aidj/all-in-one",children:"all-in-one"})," ",(0,i.jsx)(n.a,{href:"#references",children:"[1]"}),"] model to perform an initial verse/chorus split.\nNext, the community edition of ",(0,i.jsx)(n.a,{href:"https://labelstud.io/",children:"Label Studio"})," was used to align the audio sections with their corresponding lyrics.\nFor the MUSDB18 dataset, lyrics were available online for 16 tracks. For the remaining tracks, we used the ",(0,i.jsx)(n.a,{href:"https://zenodo.org/records/3989267",children:"lyrics extension"})," ",(0,i.jsx)(n.a,{href:"#references",children:"[2]"})," as a starting point and manually corrected the lyrics when necessary.\nFor JamendoLyrics, all 20 tracks had lyrics available online."]}),"\n",(0,i.jsx)(n.p,{children:"Finally, audio segments were manually reviewed and verified by five members of the Cadenza project team to ensure accuracy and consistency.\nThe final evaluation set contains 242 segments, each ranging between 10 and 20 seconds."}),"\n",(0,i.jsx)(n.h3,{id:"12-submission",children:"1.2 Submission"}),"\n",(0,i.jsxs)(n.p,{children:["Each audio segment is paired with one alpha, resulting in 242 scenes.\nThe scene needs to be processed for all listeners (51), which will result in 12,342 total processed signals to submit.\nThe evaluation processed signals need to be compressed in a single package and submitted into a repository that will be available to participants in due time.\nWe expect that submission package will size about ",(0,i.jsx)(n.strong,{children:"XX GB"}),"."]}),"\n",(0,i.jsx)(n.h2,{id:"2-task-2---rebalancing-classical-music",children:"2. Task 2 - Rebalancing Classical Music"}),"\n",(0,i.jsx)(n.p,{children:"The evaluation package contains all the audios and metadata necessary to run process the signals."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"cadenza_cad2_task2_evaluation.v1_0.tar.gz"})," ",(0,i.jsx)(n.strong,{children:"[X GB]"})," - audio and metadata evaluation."]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"21-evaluation-music",children:"2.1 Evaluation Music"}),"\n",(0,i.jsxs)(n.p,{children:["The evaluation set is based on 8 tracks from the BACH10 and 13 tracks from the URMP datasets.\nCompositions that intersect with the training sets (EnsembleSet and CadenzaWoodwind) were excluded from the evaluation.\nNote that the ",(0,i.jsx)(n.strong,{children:"Real Data for Tuning"})," tracks are also part of the BACH10 and URMP datasets, but they are not included in the evaluation."]}),"\n",(0,i.jsx)(n.p,{children:"Each track in the evaluation set were split into consecutive 15-second segments with no overlap, resulting in 87 audio segments.\nThe segments were then paired with 4 randomly selected gains and each segment-gain pair will be processed for 21 (out of 51) listeners.\nThe 21 listeners were randomly selected keeping the same distribution of listeners with moderate, moderately severe, severe and no loss."}),"\n",(0,i.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"[1]"})," Kim, Taejun and Nam, Juhan (2023), All-In-One Metrical And Functional Structure Analysis With Neighborhood Attentions on Demixed Audio, IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)\n",(0,i.jsx)(n.strong,{children:"[2]"})," Schulze-Forster, K., Doire, C.S., Richard, G. and Badeau, R., 2021. Phoneme level lyrics alignment and text-informed singing voice separation. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 29, pp.2382-2395."]})]})}function u(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},28453:(e,n,a)=>{a.d(n,{R:()=>o,x:()=>l});var i=a(96540);const t={},s=i.createContext(t);function o(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);
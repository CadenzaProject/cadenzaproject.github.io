"use strict";(self.webpackChunkclarity_cec_1=self.webpackChunkclarity_cec_1||[]).push([[8690],{3905:(e,t,a)=>{a.d(t,{Zo:()=>c,kt:()=>d});var n=a(7294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function s(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var l=n.createContext({}),p=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):s(s({},t),e)),a},c=function(e){var t=p(e.components);return n.createElement(l.Provider,{value:t},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},h=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,r=e.originalType,l=e.parentName,c=o(e,["components","mdxType","originalType","parentName"]),u=p(a),h=i,d=u["".concat(l,".").concat(h)]||u[h]||m[h]||r;return a?n.createElement(d,s(s({ref:t},c),{},{components:a})):n.createElement(d,s({ref:t},c))}));function d(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=a.length,s=new Array(r);s[0]=h;var o={};for(var l in t)hasOwnProperty.call(t,l)&&(o[l]=t[l]);o.originalType=e,o[u]="string"==typeof e?e:i,s[1]=o;for(var p=2;p<r;p++)s[p]=a[p];return n.createElement.apply(null,s)}return n.createElement.apply(null,a)}h.displayName="MDXCreateElement"},6270:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>l,toc:()=>c});var n=a(7462),i=(a(7294),a(3905)),r=(a(8209),a(4996));const s={id:"baseline",title:"Baseline",sidebar_label:"Baseline",sidebar_position:7.1},o=void 0,l={unversionedId:"icassp_2024/software/baseline",id:"icassp_2024/software/baseline",title:"Baseline",description:"Challenge entrants are supplied with a fully functioning baseline system.",source:"@site/docs/icassp_2024/software/icassp2024_baseline.mdx",sourceDirName:"icassp_2024/software",slug:"/icassp_2024/software/baseline",permalink:"/docs/icassp_2024/software/baseline",draft:!1,tags:[],version:"current",sidebarPosition:7.1,frontMatter:{id:"baseline",title:"Baseline",sidebar_label:"Baseline",sidebar_position:7.1},sidebar:"tutorialSidebar_icassp2024",previous:{title:"Software",permalink:"/docs/category/software-1"},next:{title:"Core Software",permalink:"/docs/icassp_2024/software/core_software"}},p={},c=[{value:"The <strong>Pre-Process</strong> blocks",id:"the-pre-process-blocks",level:3},{value:"The <strong>Enhancement</strong> block",id:"the-enhancement-block",level:3},{value:"The <strong>Evaluation</strong> block",id:"the-evaluation-block",level:3},{value:"References",id:"references",level:2}],u={toc:c},m="wrapper";function h(e){let{components:t,...a}=e;return(0,i.kt)(m,(0,n.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("p",null,"Challenge entrants are supplied with a fully functioning baseline system."),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"#fig2"},"Figure 2")," shows a detailed schematic of the baseline system:"),(0,i.kt)("div",{style:{textAlign:"center"}},(0,i.kt)("figure",{id:"fig2"},(0,i.kt)("img",{width:"900",src:(0,r.Z)("/img/icassp_2024/task_diagram_hrtf.png")}),(0,i.kt)("figcaption",null,"Figure 2, Detailed schematic of the baseline system."))),(0,i.kt)("p",null,"where:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Green boxes represent audio signals."),(0,i.kt)("li",{parentName:"ul"},"Blue boxes represent operations applied to the audio signals."),(0,i.kt)("li",{parentName:"ul"},"Blue database box is the anechoic HRTF dataset (audio signals)."),(0,i.kt)("li",{parentName:"ul"},"Red database box is the listener characteristics dataset (metadata information)."),(0,i.kt)("li",{parentName:"ul"},"Yellow database box is the gains dataset (metadata information)."),(0,i.kt)("li",{parentName:"ul"},"White 'Weight and sum' box is the downmix operation."),(0,i.kt)("li",{parentName:"ul"},"Solid lines are signals transferred from one state of process to the next."),(0,i.kt)("li",{parentName:"ul"},"Dashed lines are metadata information.")),(0,i.kt)("h3",{id:"the-pre-process-blocks"},"The ",(0,i.kt)("strong",{parentName:"h3"},"Pre-Process")," blocks"),(0,i.kt)("p",null,'The system starts by applying HRTFs to the music of MUSDB18-HQ dataset, simulating the music as it is picked up by the hearing aids microphones.\nThis stage is illustrated by the "pre-process enhancement" and "pre-process evaluation" boxes. However, in practice both boxes\ncorrespond to the output of the ',(0,i.kt)("inlineCode",{parentName:"p"},"generate_at_mic_musdb18.py")," script."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"First, it takes the ",(0,i.kt)("inlineCode",{parentName:"li"},"Scene")," details:",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"MUSDB18-HQ music (mixture, vocal, drums, bass, other)."),(0,i.kt)("li",{parentName:"ul"},"Subject head and loudspeaker-position (HRTFs)."))),(0,i.kt)("li",{parentName:"ul"},"It applies the HRTFs to the left and right side of all signals (mixture and VDBO components) [",(0,i.kt)("a",{parentName:"li",href:"#fig2"},"Figure 2"),"]"),(0,i.kt)("li",{parentName:"ul"},'The mixture with HRTF applied corresponds to the output of the "pre-process enhancement" block.'),(0,i.kt)("li",{parentName:"ul"},'The VDBO signals with HRTF applied correspond to the output of the "pre-process evaluation" block.')),(0,i.kt)("div",{style:{textAlign:"center"}},(0,i.kt)("figure",{id:"fig2"},(0,i.kt)("img",{width:"500",src:(0,r.Z)("/img/icassp_2024/cross-talk-hrtf.png")}),(0,i.kt)("figcaption",null,"Figure 3, The scenario."))),(0,i.kt)("h3",{id:"the-enhancement-block"},"The ",(0,i.kt)("strong",{parentName:"h3"},"Enhancement")," block"),(0,i.kt)("p",null,"The enhancement takes a mixture signal as it is picked up by the hearing aids microphones and attempts to output a personalized rebalanced stereo rendition of the music."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},'First, it takes stereo tracks ("mixture at the hearing aid mics") and demixes them into their VDBO (vocal, drums, bass and other) representation. This is done by using an out-of-the-box audio source separation system.'),(0,i.kt)("li",{parentName:"ul"},"Then, using the gains provided, the music is downmixed to stereo after changing the level of the different elements of the music."),(0,i.kt)("li",{parentName:"ul"},"Next, the downmixed signal is normalised to match the LUFS level of the input mixture."),(0,i.kt)("li",{parentName:"ul"},"NAL-R amplification is applied to the normalised downmixed signal, allowing for a personalised amplification for the listener using a standard hearing aid algorithm."),(0,i.kt)("li",{parentName:"ul"},"This amplified signal is the output of the system: ",(0,i.kt)("inlineCode",{parentName:"li"},"Processed signal"))),(0,i.kt)("h3",{id:"the-evaluation-block"},"The ",(0,i.kt)("strong",{parentName:"h3"},"Evaluation")," block"),(0,i.kt)("p",null,"The evaluation generates the reference and processed signals and computes the HAAQI score."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"First, it takes the VDBO signals at the hearing aid microphones (these are the VDBO components provided by MUSDB18-HQ with the HRTF applied to them) and remixes the signals using the same gains as applied in the enhancement."),(0,i.kt)("li",{parentName:"ul"},'Then, it normalises the remix to the same LUFS level as the "mixture at the hearing aid mics".'),(0,i.kt)("li",{parentName:"ul"},"Next, it applies the NAL-R amplification."),(0,i.kt)("li",{parentName:"ul"},"This process results in the ",(0,i.kt)("inlineCode",{parentName:"li"},"Reference signal"),' for HAAQI, which simulates a "listener preferred mixture". The reference signal corresponds to an ideal rebalanced signal when we have access to the clean VDBO components.'),(0,i.kt)("li",{parentName:"ul"},"As HAAQI is an intrusive metric, the score is computed by comparing the ",(0,i.kt)("inlineCode",{parentName:"li"},"Processed signal")," (downmixed music) with the ",(0,i.kt)("inlineCode",{parentName:"li"},"Reference signal"),", focussing on changes to time-frequency envelope modulation, temporal fine structure and long-term spectrum.")),(0,i.kt)("admonition",{title:"Note",type:"info"},(0,i.kt)("ul",{parentName:"admonition"},(0,i.kt)("li",{parentName:"ul"},"In the Enhancement and Evaluation blocks, we apply a loudness normalisation (in ",(0,i.kt)("a",{parentName:"li",href:"https://www.izotope.com/en/learn/what-are-lufs.html"},"LUFS"),") after applying the gains.\nThis is to keep the loudness of the remix at the same levels as the mixture at the hearing aid mics."),(0,i.kt)("li",{parentName:"ul"},"As required by HAAQI, we resample both the reference and processed signal before computing the score."))),(0,i.kt)("h2",{id:"references"},"References"),(0,i.kt)("a",{name:"refs"}),(0,i.kt)("p",null,"[1]"," Kates, J.M.  and Arehart, K.H., 2016. The Hearing-Aid Audio Quality Index (HAAQI), in IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 24, no. 2, pp. 354-365, doi: 10.1109/TASLP.2015.2507858."))}h.isMDXComponent=!0},8209:(e,t,a)=>{a(7294)}}]);
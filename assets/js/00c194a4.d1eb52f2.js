"use strict";(self.webpackChunkclarity_cec_1=self.webpackChunkclarity_cec_1||[]).push([[1556],{3905:(e,t,a)=>{a.d(t,{Zo:()=>c,kt:()=>m});var n=a(7294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var s=n.createContext({}),p=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},c=function(e){var t=p(e.components);return n.createElement(s.Provider,{value:t},e.children)},h="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,r=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),h=p(a),d=i,m=h["".concat(s,".").concat(d)]||h[d]||u[d]||r;return a?n.createElement(m,o(o({ref:t},c),{},{components:a})):n.createElement(m,o({ref:t},c))}));function m(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=a.length,o=new Array(r);o[0]=d;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[h]="string"==typeof e?e:i,o[1]=l;for(var p=2;p<r;p++)o[p]=a[p];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}d.displayName="MDXCreateElement"},1966:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>l,default:()=>d,frontMatter:()=>o,metadata:()=>s,toc:()=>c});var n=a(7462),i=(a(7294),a(3905)),r=(a(8209),a(4996));a(7061);const o={id:"intro",title:"The ICASSP 2024 Cadenza Grand Challenge",sidebar_label:"ICASSP 2024 Introduction",sidebar_position:1},l=void 0,s={unversionedId:"icassp_2024/intro",id:"icassp_2024/intro",title:"The ICASSP 2024 Cadenza Grand Challenge",description:"Please, refer to the challenge timeline to know when the datasets and software will be available.",source:"@site/docs/icassp_2024/icassp_2024_intro.md",sourceDirName:"icassp_2024",slug:"/icassp_2024/intro",permalink:"/docs/icassp_2024/intro",draft:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{id:"intro",title:"The ICASSP 2024 Cadenza Grand Challenge",sidebar_label:"ICASSP 2024 Introduction",sidebar_position:1},sidebar:"tutorialSidebar_icassp2024",next:{title:"The Challenge Data",permalink:"/docs/category/the-challenge-data-1"}},p={},c=[{value:"Why this challenge?",id:"why-this-challenge",level:2},{value:"The Task",id:"the-task",level:2},{value:"Data",id:"data",level:2},{value:"Output",id:"output",level:2},{value:"Evaluation Stage",id:"evaluation-stage",level:2}],h={toc:c},u="wrapper";function d(e){let{components:t,...a}=e;return(0,i.kt)(u,(0,n.Z)({},h,a,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("admonition",{type:"info"},(0,i.kt)("p",{parentName:"admonition"},"Please, refer to the challenge ",(0,i.kt)("a",{parentName:"p",href:"take_part/key_dates"},"timeline")," to know when the datasets and software will be available.\nMeanwhile, go through the website to familiarise with the challenge.")),(0,i.kt)("h1",{id:"overview"},"Overview"),(0,i.kt)("p",null,"Someone with a hearing loss is listening to music via their hearing aids or headphones.\nThe challenge is to develop a signal processing system that allows a personalised rebalancing of the music to\nimprove the listening experience, for example by amplifying the vocals relative to the sound of the band.\nOne approach to this would be to a demix the music and then apply gains to the separated tracks to change the balance when the music is downmixed to stereo."),(0,i.kt)("h2",{id:"why-this-challenge"},"Why this challenge?"),(0,i.kt)("p",null,"There is a global challenge of an ageing population, which will contribute to 1 in 10 people having disabling hearing loss by 2050. Hearing loss causes problems when listening to music. It can make picking out lyrics more difficult, with music becoming duller as high frequencies disappear. This reduces the enjoyment of music and can lead to disengagement from listening and music-making, reducing the health and well-being effects people otherwise get from music. We want to get more of the ICASSP community to consider diverse hearing and so allow those with a hearing loss to benefit from the latest signal processing advances."),(0,i.kt)("h2",{id:"the-task"},"The Task"),(0,i.kt)("p",null,"As Figure 1 shows, the ",(0,i.kt)("strong",{parentName:"p"},"Enhancement"),' block first demixes stereo tracks ("original stereo mixture") into a VDBO (vocal, drums, bass and other) representation.\nThis then allows a personalised remixing for the listener by changing the level of the different elements of the music.\nWe provide the desired gains for the remixing.\nThe "NAL-R" amplification is a standard way of compensating for the hearing loss of the listeners. '),(0,i.kt)("p",null,"The ",(0,i.kt)("strong",{parentName:"p"},"Evaluation")," block, generates the ",(0,i.kt)("em",{parentName:"p"},"reference")," signal by applying the same gains used in the Enhancement.\nThis reference signal corresponds to a simulated ",(0,i.kt)("em",{parentName:"p"},"preferred music mixture")," by a listener with a hearing loss."),(0,i.kt)("p",null,"In the Enhancement and Evaluation blocks, we apply a LUFS normalisation after applying the gains to keep the level of the new mixture\nequal to the level of the original stereo mixture."),(0,i.kt)("p",null,"To evaluate the quality of the remixing, we will use the objective metric\n",(0,i.kt)("a",{parentName:"p",href:"../learning_resources/Hearing_aid_processing/edu_HAP_HA_processed_speech#haaqi-hearing-aid-audio-quality-index"},"HAAQI (Hearing aid audio quality index)"),"."),(0,i.kt)("figure",{id:"fig1"},(0,i.kt)("img",{width:"950",src:(0,r.Z)("/img/icassp_2024/task_diagram.png")}),(0,i.kt)("figcaption",null,"Figure 1, The baseline system.")),(0,i.kt)("p",null,"The block that can be changed by you is labelled ",(0,i.kt)("em",{parentName:"p"},"Enhancement")," in Figure 1.\nWhile the baseline frames the problem as demixing/remixing, alternative approaches are very welcome.\nWe are interested in systems that are either: (i) causal and low latency for live music, and (ii) non-causal for recorded music."),(0,i.kt)("h2",{id:"data"},"Data"),(0,i.kt)("p",null,"In the enhancement stage, you have access to:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"Full length songs from MUSDB18-HQ dataset."),(0,i.kt)("li",{parentName:"ol"},"Music data for augmentation, if needed. "),(0,i.kt)("li",{parentName:"ol"},"Listeners characteristics (audiograms)")),(0,i.kt)("ol",{start:4},(0,i.kt)("li",{parentName:"ol"},"Target gains for the VDBO stems used to mix the target stereo")),(0,i.kt)("p",null,"Please refer to ",(0,i.kt)("a",{parentName:"p",href:"data/data_overview"},"data page")," for details."),(0,i.kt)("p",null,"To download the datasets, please visit ",(0,i.kt)("a",{parentName:"p",href:"take_part/download"},"download data and software")," "),(0,i.kt)("h2",{id:"output"},"Output"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"One stereo downmixed signal",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Sample rate = 32000 Hz"),(0,i.kt)("li",{parentName:"ul"},"Precision: 16bit integer"),(0,i.kt)("li",{parentName:"ul"},"Compressed using FLAC")))),(0,i.kt)("p",null,"For more details about the format of the submission, please refer to the ",(0,i.kt)("a",{parentName:"p",href:"take_part/submission"},"submission")," webpage."),(0,i.kt)("admonition",{title:"Note",type:"caution"},(0,i.kt)("p",{parentName:"admonition"},"The responsibility for the final remixed signal level is yours.\nIt\u2019s worth bearing in mind there may be clipping in the evaluation block in some tasks\nif the processed signals are too large.")),(0,i.kt)("h2",{id:"evaluation-stage"},"Evaluation Stage"),(0,i.kt)("admonition",{title:"Warning",type:"danger"},(0,i.kt)("p",{parentName:"admonition"},"You are not allowed to change the ",(0,i.kt)("strong",{parentName:"p"},"evaluation")," script provided in the baseline.\nYour output signals with be scored using this script.")),(0,i.kt)("p",null,"The evaluation stage computes HAAQI scores for the remixed stereo. To learn more about HAAQI, please refer to our ",(0,i.kt)("a",{parentName:"p",href:"../learning_resources/Hearing_aid_processing/edu_HAP_HA_processed_speech"},"Learning Resources"),"\nand to our Python ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/claritychallenge/clarity/blob/main/clarity/evaluator/haaqi/haaqi.py"},"HAAQI implementation"),". "),(0,i.kt)("p",null,"The output of the evaluation stage is a CSV file with all the HAAQI scores. "))}d.isMDXComponent=!0},8209:(e,t,a)=>{a(7294)}}]);
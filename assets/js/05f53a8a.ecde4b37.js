"use strict";(self.webpackChunkclarity_cec_1=self.webpackChunkclarity_cec_1||[]).push([[606],{3905:(e,t,a)=>{a.d(t,{Zo:()=>m,kt:()=>h});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=n.createContext({}),p=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},m=function(e){var t=p(e.components);return n.createElement(l.Provider,{value:t},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,m=s(e,["components","mdxType","originalType","parentName"]),c=p(a),d=r,h=c["".concat(l,".").concat(d)]||c[d]||u[d]||i;return a?n.createElement(h,o(o({ref:t},m),{},{components:a})):n.createElement(h,o({ref:t},m))}));function h(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,o=new Array(i);o[0]=d;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[c]="string"==typeof e?e:r,o[1]=s;for(var p=2;p<i;p++)o[p]=a[p];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}d.displayName="MDXCreateElement"},3596:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>o,metadata:()=>l,toc:()=>m});var n=a(7462),r=(a(7294),a(3905)),i=(a(8209),a(4996));a(7061);const o={id:"cc1_summary_task1",title:"Summary Task 1",sidebar_label:"Summary Task 1",sidebar_position:2},s=void 0,l={unversionedId:"cadenza1/cc1_summary_task1",id:"cadenza1/cc1_summary_task1",title:"Summary Task 1",description:"If you have a pretrained music source separation trained only using the allowed datasets, you can easily enter our challenge.",source:"@site/docs/cadenza1/cc1_summary_task1.md",sourceDirName:"cadenza1",slug:"/cadenza1/cc1_summary_task1",permalink:"/docs/cadenza1/cc1_summary_task1",draft:!1,tags:[],version:"current",sidebarPosition:2,frontMatter:{id:"cc1_summary_task1",title:"Summary Task 1",sidebar_label:"Summary Task 1",sidebar_position:2},sidebar:"tutorialSidebar1",previous:{title:"Cadenza 1 Introduction",permalink:"/docs/cadenza1/cc1_intro"},next:{title:"Summary Task 2",permalink:"/docs/cadenza1/cc1_summary_task2"}},p={},m=[{value:"1. Description of the Problem",id:"1-description-of-the-problem",level:2},{value:"1.1 Enhancement Stage",id:"11-enhancement-stage",level:3},{value:"1.1.1 Dataset",id:"111-dataset",level:4},{value:"1.1.2 Output",id:"112-output",level:4},{value:"1.2 Evaluation Stage",id:"12-evaluation-stage",level:3},{value:"2. Software",id:"2-software",level:2},{value:"3. Baselines",id:"3-baselines",level:2},{value:"4. Leaderboard",id:"4-leaderboard",level:2}],c={toc:m},u="wrapper";function d(e){let{components:t,...a}=e;return(0,r.kt)(u,(0,n.Z)({},c,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("admonition",{title:"Participate",type:"tip"},(0,r.kt)("p",{parentName:"admonition"},"If you have a pretrained music source separation trained only using the allowed datasets, you can easily enter our challenge."),(0,r.kt)("p",{parentName:"admonition"},"We invite you to make a copy of the baseline, adapt the enhancement script to use your separation model and\nrun the whole system to obtain HAAQI scores. You might need to amplify your separated signals to match the amplification of the reference done by HAAQI."),(0,r.kt)("p",{parentName:"admonition"},"Then, you can explore ways to improve the remix stage to generate better and personalised signals for listeners."),(0,r.kt)("admonition",{parentName:"admonition",title:"Remember",type:"danger"},(0,r.kt)("p",{parentName:"admonition"},"After the objective evaluation we will run subjective evaluation using a listeners panel of 50 listeners.\nWe will share the results of your system with you so you can use them in a paper."))),(0,r.kt)("h2",{id:"1-description-of-the-problem"},"1. Description of the Problem"),(0,r.kt)("p",null,"A person with a hearing loss is listening to music via headphones. They're not using their hearing aids. "),(0,r.kt)("p",null,"The machine learning task is to decompose a stereo song into a VDBO (vocal, drums, bass and other) representation.\nThis then allows a personalised remixing for the listener that has better audio quality.\nFor example, for some music you might amplify the vocals to improve the audibility of the lyrics."),(0,r.kt)("p",null,"As shown in Figure [",(0,r.kt)("a",{parentName:"p",href:"#fig1"},"1"),"], the system is split into two stages; the ",(0,r.kt)("em",{parentName:"p"},"enhancement")," and ",(0,r.kt)("em",{parentName:"p"},"evaluation"),"."),(0,r.kt)("figure",{id:"fig1"},(0,r.kt)("img",{width:"800",src:(0,i.Z)("/img/headphone_simple_v3.png")}),(0,r.kt)("figcaption",null,"Figure 1, The baseline for the headphone listening scenario. For simplicity, not all signal paths are shown.")),(0,r.kt)("h3",{id:"11-enhancement-stage"},"1.1 Enhancement Stage"),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"You can adapt and modify the baseline ",(0,r.kt)("strong",{parentName:"p"},"enhancement")," script or make your own script.")),(0,r.kt)("p",null,"Your task is to decompose a stereo music signal and produce 8 mono signals or stems corresponding to the\nright and left ",(0,r.kt)("inlineCode",{parentName:"p"},"vocal"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"drums"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"bass")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"other")," (VDBO), and produce one stereo signal corresponding to a\nremix signal optimised for a target listener.\nFor this, you will have access to relevant datasets that will allow you to explore different approaches to separate the music and/or to remix the signals.  "),(0,r.kt)("h4",{id:"111-dataset"},"1.1.1 Dataset"),(0,r.kt)("p",null,"In the enhancement stage, you have access to:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Full length songs from MUSDB18-HQ dataset."),(0,r.kt)("li",{parentName:"ol"},"Music data for augmentation, if needed. "),(0,r.kt)("li",{parentName:"ol"},"Listeners characteristics (audiograms). ",(0,r.kt)("a",{parentName:"li",href:"Data/cc1_data_listener"},"Listener Data"))),(0,r.kt)("p",null,"Please refer to ",(0,r.kt)("a",{parentName:"p",href:"Data/cc1_data_overview"},"task 1 data page")," and\nthe ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/claritychallenge/clarity/tree/main/recipes/cad1/task1/baseline"},"baseline readme")," for details."),(0,r.kt)("p",null,"To download the datasets, please visit ",(0,r.kt)("a",{parentName:"p",href:"Take%20part/cc1_download#21-task-1---headphones"},"download data and software"),"."),(0,r.kt)("h4",{id:"112-output"},"1.1.2 Output"),(0,r.kt)("p",null,"The output of this stage are:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Eight stems corresponding to the left and right vocal, bass, drums and other stems.",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Sample rate = 24000 Hz"),(0,r.kt)("li",{parentName:"ul"},"Precision: 16bit integer"),(0,r.kt)("li",{parentName:"ul"},"Compressed using FLAC"))),(0,r.kt)("li",{parentName:"ol"},"One stereo remixed signal",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Sample rate = 32000 Hz"),(0,r.kt)("li",{parentName:"ul"},"Precision: 16bit integer"),(0,r.kt)("li",{parentName:"ul"},"Compressed using FLAC")))),(0,r.kt)("p",null,"For more details about the format of the submission, please refer to the ",(0,r.kt)("a",{parentName:"p",href:"Take%20part/cc1_submission"},"submission")," webpage."),(0,r.kt)("admonition",{title:"Note",type:"caution"},(0,r.kt)("p",{parentName:"admonition"},"The responsibility for the final remixed signal level is yours.\nIt\u2019s worth bearing in mind that should your signals overall seem too loud to be comfortable to a participant,\nthey may well turn down the volume themselves. Also, there may be clipping in the evaluation block in some tasks\nif the processed signals are too large.")),(0,r.kt)("h3",{id:"12-evaluation-stage"},"1.2 Evaluation Stage"),(0,r.kt)("admonition",{title:"Warning",type:"danger"},(0,r.kt)("p",{parentName:"admonition"},"You are not allowed to change the ",(0,r.kt)("strong",{parentName:"p"},"evaluation")," script provided in the baseline.\nYour output signals with be scored using this script.")),(0,r.kt)("p",null,"The evaluation stage is a common stage for all submissions.\nAs shown in Figure [",(0,r.kt)("a",{parentName:"p",href:"#fig1"},"1"),"], the evaluation takes the reference stem signals, i.e., the eight reference stems,\nand the eight processed stems and computes the eight HAAQI scores."),(0,r.kt)("p",null,"To learn more about HAAQI, please refer to our ",(0,r.kt)("a",{parentName:"p",href:"../learning_resources/Hearing_aid_processing/edu_HAP_HA_processed_speech"},"Learning Resources"),"\nand to our Python ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/claritychallenge/clarity/blob/cad1task1-baseline2/clarity/evaluator/haaqi/haaqi.py"},"HAAQI implementation"),". "),(0,r.kt)("p",null,"The output of the evaluation stage is a CSV file with all the HAAQI scores. "),(0,r.kt)("h2",{id:"2-software"},"2. Software"),(0,r.kt)("p",null,"All the necessary software to run the recipes and make your own submission is available on our ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/claritychallenge/clarity"},"Clarity-Cadenza\nGitHub repository"),"."),(0,r.kt)("p",null,"The official code for the first challenge was released in version ",(0,r.kt)("inlineCode",{parentName:"p"},"v0.3.2"),".\nTo avoid any conflict, we highly recommend for you to work using version v0.3.2 and\nnot with the code from the ",(0,r.kt)("inlineCode",{parentName:"p"},"main")," branch. To install this version:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Download the files of the release v0.3.2 from:\n",(0,r.kt)("a",{parentName:"p",href:"https://github.com/claritychallenge/clarity/releases/tag/v0.3.2"},"https://github.com/claritychallenge/clarity/releases/tag/v0.3.2"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Clone the repository and checkout version v0.3.2"))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"git clone https://github.com/claritychallenge/clarity.git\ngit checkout tags/v0.3.2\n")),(0,r.kt)("ol",{start:3},(0,r.kt)("li",{parentName:"ol"},"Install pyclarity from PyPI as:")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"pip install pyclarity==0.3.3\n")),(0,r.kt)("h2",{id:"3-baselines"},"3. Baselines"),(0,r.kt)("p",null,"In the ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/claritychallenge/clarity"},"Clarity/Cadenza GitHub repository"),", we provide two baselines.\nBoth baseline systems work in a similar way. Using a music source separation model, the systems\ndecompose the music into the target eight stems. Both models were trained exclusively on MUSDB18-HQ training set and no\nextra data was used for augmentation."),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("inlineCode",{parentName:"li"},"Demucs"),": This baseline system uses the ",(0,r.kt)("inlineCode",{parentName:"li"},"Hybrid Demucs")," model. This is a time-domain-based model."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("inlineCode",{parentName:"li"},"Open-UnMix"),": This baseline system uses the ",(0,r.kt)("inlineCode",{parentName:"li"},"umxhq")," model from Open-UnMix. This is a spectrogram-based model.")),(0,r.kt)("p",null,"Please, visit the ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/claritychallenge/clarity/tree/cad1task1-baseline2/recipes/cad1/task1/baseline"},"baseline on the GitHub webpage"),"\nand ",(0,r.kt)("a",{parentName:"p",href:"Software/cc1_baseline#1-task-1-headphones"},"Baseline")," links to read more about the baselines and learn how to run them."),(0,r.kt)("h2",{id:"4-leaderboard"},"4. Leaderboard"),(0,r.kt)("admonition",{title:"Participate in our Leaderboard",type:"tip"},(0,r.kt)("p",{parentName:"admonition"},"If you have scores using the validation set, send us the ",(0,r.kt)("inlineCode",{parentName:"p"},"score.csv")," file, and we will include you.")),(0,r.kt)("p",null,"The score used for the ranking is the average over all examples."),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Ranking"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Team"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Average score"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},"1"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Baseline Demucs"),(0,r.kt)("td",{parentName:"tr",align:"center"},"0.2592")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},"2"),(0,r.kt)("td",{parentName:"tr",align:"left"},"Baseline OpenUnMix"),(0,r.kt)("td",{parentName:"tr",align:"center"},"0.2273")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},"3"),(0,r.kt)("td",{parentName:"tr",align:"left"},"xumx_slicq_v2"),(0,r.kt)("td",{parentName:"tr",align:"center"},"0.2046")))))}d.isMDXComponent=!0},8209:(e,t,a)=>{a(7294)}}]);